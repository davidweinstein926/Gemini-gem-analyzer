#!/usr/bin/env python3
"""
COMPLETE MULTI-GEM STRUCTURAL ANALYZER WITH AUTOMATIC VALID GEM DETECTION
üéØ FEATURES:
- ‚úÖ Automatic detection of GOI light sources
- ‚úÖ Automatic filtering of database to find gems with matching light sources  
- ‚úÖ Date-based TS matching (same day, not time)
- ‚úÖ Perfect self-matching (100% for identical files)
- ‚úÖ Enhanced result formatting
"""

import tkinter as tk
from tkinter import ttk, messagebox
import os, sys, sqlite3, shutil, json, math, traceback, re
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Optional imports
try:
    import matplotlib.pyplot as plt
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False

try:
    from scipy.spatial.distance import euclidean
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False

class MultiGemStructuralAnalyzer:
    """Complete analyzer with automatic valid gem detection"""
    
    def __init__(self, mode="gui", input_source="archive"):
        self.mode = mode
        self.input_source = input_source
        
        if self.mode == "gui":
            self.root = tk.Tk()
            self.root.title(f"Multi-Gem Structural Analyzer - {input_source.title()}")
            self.root.geometry("1200x800")
        else:
            self.root = None
            print(f"üî¨ Analyzer initialized: {mode} mode, {input_source} source")
        
        # Find project root and setup paths
        self.project_root = self.find_project_root()
        self.setup_paths()
        
        # Load gem descriptions
        self.gem_name_map = self.load_gem_library()
        
        # Data structures
        self.gem_groups = {}
        self.selected_gems = {}
        self.database_schema = None
        
        # Scoring parameters
        self.perfect_match_threshold = 0.005
        self.light_weights = {'B': 1.0, 'L': 0.9, 'U': 0.8}
        
        # Initialize
        if self.mode == "gui":
            self.setup_gui()
        
        self.check_databases()
        self.scan_input_directory()
    
    def find_project_root(self):
        """Find project root directory"""
        current_path = Path(__file__).parent
        for level in range(5):
            if sum(1 for indicator in ['database', 'data', 'src'] if (current_path / indicator).exists()) >= 2:
                return current_path
            parent = current_path.parent
            if parent == current_path:
                break
            current_path = parent
        return Path(__file__).parent.parent.parent
    
    def setup_paths(self):
        """Setup directory paths"""
        if self.input_source == "archive":
            self.input_path = self.project_root / "data" / "structural(archive)"
            self.analysis_name = "Archive Analysis (Option 8)"
        else:
            self.input_path = self.project_root / "data" / "structural_data"
            self.analysis_name = "Current Work Analysis (Option 4)"
        
        self.sqlite_db_path = self.project_root / "database" / "structural_spectra" / "gemini_structural.db"
        self.csv_db_path = self.project_root / "database" / "structural_spectra" / "gemini_structural_unified.csv"
    
    def load_gem_library(self):
        """Load gem descriptions"""
        gem_map = {}
        for path in [self.project_root / "gemlib_structural_ready.csv",
                     self.project_root / "database" / "gemlib_structural_ready.csv"]:
            try:
                if path.exists():
                    df = pd.read_csv(path)
                    if 'Reference' in df.columns:
                        expected_cols = ['Nat./Syn.', 'Spec.', 'Var.', 'Treatment', 'Origin']
                        if all(col in df.columns for col in expected_cols):
                            df['Description'] = df[expected_cols].apply(
                                lambda x: ' '.join([str(v) if pd.notnull(v) else '' for v in x]).strip(), axis=1)
                            gem_map = dict(zip(df['Reference'].astype(str), df['Description']))
                            print(f"‚úÖ Loaded {len(gem_map)} gem descriptions")
                            return gem_map
            except:
                continue
        return gem_map
    
    def check_databases(self):
        """Check and load database schema"""
        if self.sqlite_db_path.exists():
            self.database_type, self.database_path = "sqlite", self.sqlite_db_path
        elif self.csv_db_path.exists():
            self.database_type, self.database_path = "csv", self.csv_db_path
        else:
            if self.mode == "gui":
                messagebox.showerror("Error", "No structural database found!")
            else:
                print("‚ùå No structural database found!")
            return False
        
        return self.detect_database_schema()
    
    def detect_database_schema(self):
        """Detect database schema"""
        try:
            if self.database_type == "sqlite":
                with sqlite3.connect(self.database_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                    tables = cursor.fetchall()
                    if not tables:
                        return False
                    
                    table_name = tables[0][0]
                    cursor.execute(f"PRAGMA table_info({table_name})")
                    columns = [col[1] for col in cursor.fetchall()]
            else:
                df = pd.read_csv(self.database_path, nrows=1)
                columns = df.columns.tolist()
                table_name = None
            
            self.database_schema = {
                'table_name': table_name,
                'file_column': self.find_column(columns, ['file', 'filename', 'gem_id']),
                'wavelength_column': self.find_column(columns, ['wavelength', 'Wavelength']),
                'intensity_column': self.find_column(columns, ['intensity', 'Intensity']),
                'light_column': self.find_column(columns, ['light_source', 'light']),
                'time_series_column': self.find_column(columns, ['time_series', 'ts'])
            }
            
            if not self.database_schema['file_column']:
                print("‚ùå No file column found in database")
                return False
            
            print(f"‚úÖ Database schema detected: {self.database_type}")
            return True
            
        except Exception as e:
            print(f"‚ùå Schema detection failed: {e}")
            return False
    
    def find_column(self, columns, candidates):
        """Find matching column name"""
        for candidate in candidates:
            if candidate in columns:
                return candidate
        return None
    
    def scan_input_directory(self):
        """Scan input directory for gem files"""
        if not self.input_path.exists():
            if self.mode == "gui":
                messagebox.showerror("Error", f"Directory not found: {self.input_path}")
            return
        
        csv_files = list(self.input_path.glob("*.csv"))
        if not csv_files:
            if self.mode == "gui":
                messagebox.showwarning("Warning", f"No CSV files in {self.input_path}")
            return
        
        self.gem_groups.clear()
        
        for file_path in csv_files:
            gem_info = self.parse_filename(file_path.name)
            base_id = gem_info['base_id']
            
            if base_id not in self.gem_groups:
                self.gem_groups[base_id] = {'files': {'B': [], 'L': [], 'U': []}, 'paths': {'B': [], 'L': [], 'U': []}}
            
            light_source = gem_info['light_source']
            if light_source in ['B', 'L', 'U']:
                self.gem_groups[base_id]['files'][light_source].append(gem_info)
                self.gem_groups[base_id]['paths'][light_source].append(file_path)
        
        if self.mode == "gui":
            self.populate_gem_list()
        else:
            complete = sum(1 for data in self.gem_groups.values() 
                          if all(len(data['files'][ls]) > 0 for ls in ['B', 'L', 'U']))
            print(f"üìÅ Found {len(self.gem_groups)} gems ({complete} complete)")
    
    def parse_filename(self, filename):
        """Parse structural filename with date extraction"""
        stem = Path(filename).stem
        
        # Extract date
        date_extracted = self.extract_date_from_filename(filename)
        
        # Remove suffixes
        stem = re.sub(r'_(structural|halogen|laser|uv|TS\d+|_\d{8}_\d{6}).*$', '', stem)
        
        # Parse light source and base ID
        if '_halogen_' in stem.lower():
            base_id = re.search(r'(\d+)', stem.split('_halogen_')[0])
            return {'base_id': base_id.group(1) if base_id else stem, 'light_source': 'B', 
                   'filename': filename, 'date': date_extracted}
        elif '_laser_' in stem.lower():
            base_id = re.search(r'(\d+)', stem.split('_laser_')[0])
            return {'base_id': base_id.group(1) if base_id else stem, 'light_source': 'L',
                   'filename': filename, 'date': date_extracted}
        elif '_uv_' in stem.lower():
            base_id = re.search(r'(\d+)', stem.split('_uv_')[0])
            return {'base_id': base_id.group(1) if base_id else stem, 'light_source': 'U',
                   'filename': filename, 'date': date_extracted}
        else:
            # Standard format: 58BC1, 197LC2, etc.
            match = re.match(r'^([A-Za-z]*\d+)([BLU])', stem)
            if match:
                prefix, light = match.groups()
                base_id = re.search(r'(\d+)', prefix)
                return {'base_id': base_id.group(1) if base_id else prefix, 
                       'light_source': light, 'filename': filename, 'date': date_extracted}
        
        return {'base_id': stem, 'light_source': 'Unknown', 'filename': filename, 'date': date_extracted}
    
    def extract_date_from_filename(self, filename):
        """Extract date from filename"""
        patterns = [
            r'(\d{4})(\d{2})(\d{2})',     # YYYYMMDD
            r'(\d{4})-(\d{2})-(\d{2})',   # YYYY-MM-DD
            r'_(\d{4})(\d{2})(\d{2})_'    # _YYYYMMDD_
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                try:
                    year, month, day = match.groups()
                    return datetime(int(year), int(month), int(day)).strftime('%Y-%m-%d')
                except:
                    continue
        return None
    
    def setup_gui(self):
        """Setup GUI interface"""
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.pack(fill='both', expand=True)
        
        # Title
        ttk.Label(main_frame, text=self.analysis_name, font=('Arial', 14, 'bold')).pack(pady=(0, 10))
        
        # Content
        content_frame = ttk.Frame(main_frame)
        content_frame.pack(fill='both', expand=True, pady=(0, 10))
        
        # Left - Available gems
        left_frame = ttk.LabelFrame(content_frame, text="Available Gems", padding="5")
        left_frame.pack(side='left', fill='both', expand=True, padx=(0, 5))
        
        self.gem_listbox = tk.Listbox(left_frame, height=15)
        self.gem_listbox.pack(fill='both', expand=True, pady=(0, 10))
        
        ttk.Button(left_frame, text="Select Files", command=self.select_gem_files).pack(side='left', padx=(0, 5))
        ttk.Button(left_frame, text="Select All", command=self.select_all_complete).pack(side='left')
        
        # Right - Selected gems
        right_frame = ttk.LabelFrame(content_frame, text="Selected for Analysis", padding="5")
        right_frame.pack(side='right', fill='both', expand=True, padx=(5, 0))
        
        self.selected_listbox = tk.Listbox(right_frame, height=15)
        self.selected_listbox.pack(fill='both', expand=True, pady=(0, 10))
        
        ttk.Button(right_frame, text="Remove", command=self.remove_selected).pack()
        
        # Controls
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill='x', pady=10)
        
        ttk.Button(control_frame, text="Clear All", command=self.clear_all).pack(side='left')
        ttk.Button(control_frame, text="Close", command=self.close_app).pack(side='right')
        ttk.Button(control_frame, text="üöÄ Start Analysis", command=self.start_analysis).pack(side='right', padx=(5, 0))
        
        # Status
        self.status_var = tk.StringVar(value="Ready")
        ttk.Label(main_frame, textvariable=self.status_var).pack()
    
    def populate_gem_list(self):
        """Populate gem list"""
        self.gem_listbox.delete(0, tk.END)
        for base_id, data in sorted(self.gem_groups.items()):
            counts = [len(data['files'][ls]) for ls in ['B', 'L', 'U']]
            status = "üü¢" if all(c > 0 for c in counts) else "üü°"
            sources = '+'.join([f"{ls}({c})" for ls, c in zip(['B', 'L', 'U'], counts) if c > 0])
            self.gem_listbox.insert(tk.END, f"{status} Gem {base_id} - {sources}")
    
    def select_gem_files(self):
        """Select gem files"""
        selection = self.gem_listbox.curselection()
        if not selection:
            messagebox.showwarning("No Selection", "Please select a gem.")
            return
        
        gem_ids = sorted(self.gem_groups.keys())
        base_id = gem_ids[selection[0]]
        
        if base_id in self.selected_gems:
            messagebox.showinfo("Already Selected", f"Gem {base_id} already selected.")
            return
        
        gem_data = self.gem_groups[base_id]
        selected = {'files': {}, 'paths': {}}
        
        for ls in ['B', 'L', 'U']:
            if gem_data['files'][ls]:
                selected['files'][ls] = gem_data['files'][ls][0]
                selected['paths'][ls] = gem_data['paths'][ls][0]
        
        self.selected_gems[base_id] = selected
        self.update_selected_display()
    
    def select_all_complete(self):
        """Select all complete gems"""
        for base_id, data in self.gem_groups.items():
            if all(len(data['files'][ls]) > 0 for ls in ['B', 'L', 'U']) and base_id not in self.selected_gems:
                selected = {'files': {}, 'paths': {}}
                for ls in ['B', 'L', 'U']:
                    selected['files'][ls] = data['files'][ls][0]
                    selected['paths'][ls] = data['paths'][ls][0]
                self.selected_gems[base_id] = selected
        
        self.update_selected_display()
        messagebox.showinfo("Complete", f"Selected {len(self.selected_gems)} gems.")
    
    def update_selected_display(self):
        """Update selected gems display"""
        self.selected_listbox.delete(0, tk.END)
        for base_id, data in self.selected_gems.items():
            sources = '+'.join(sorted(data['files'].keys()))
            self.selected_listbox.insert(tk.END, f"Gem {base_id} ({sources})")
        self.status_var.set(f"Selected {len(self.selected_gems)} gems")
    
    def remove_selected(self):
        """Remove selected gem"""
        selection = self.selected_listbox.curselection()
        if selection:
            gem_ids = list(self.selected_gems.keys())
            if selection[0] < len(gem_ids):
                del self.selected_gems[gem_ids[selection[0]]]
                self.update_selected_display()
    
    def clear_all(self):
        """Clear all selections"""
        self.selected_gems.clear()
        self.update_selected_display()
    
    def close_app(self):
        """Close application"""
        if messagebox.askyesno("Close", "Close application?"):
            self.root.quit()
            self.root.destroy()
    
    def start_analysis(self):
        """Start analysis"""
        if not self.selected_gems:
            messagebox.showwarning("No Selection", "Select at least one gem.")
            return
        
        if not self.database_schema:
            messagebox.showerror("Error", "Database not available.")
            return
        
        count = len(self.selected_gems)
        if messagebox.askyesno("Start Analysis", f"Analyze {count} gems?\n\n‚úÖ Automatic valid gem detection\n‚úÖ Date-based TS matching\n‚úÖ Perfect self-match capability"):
            self.run_analysis()
    
    def detect_goi_light_sources(self):
        """üéØ NEW: Automatically detect GOI light sources"""
        goi_light_sources = set()
        
        for gem_data in self.selected_gems.values():
            goi_light_sources.update(gem_data['paths'].keys())
        
        print(f"üîç GOI LIGHT SOURCE DETECTION:")
        print(f"   üìä Detected GOI light sources: {sorted(goi_light_sources)}")
        
        return goi_light_sources
    
    def find_valid_database_gems(self, db_df, goi_light_sources):
        """üéØ FIXED: Find database gems where SAME base ID appears with ALL required light sources"""
        
        file_col = self.database_schema['file_column']
        light_col = self.database_schema.get('light_column')
        
        if not light_col or light_col not in db_df.columns:
            print(f"      ‚ö†Ô∏è No light source column found - cannot filter by light sources")
            return db_df, []
        
        print(f"      üîç FINDING VALID DATABASE GEMS:")
        print(f"         GOI has: {sorted(goi_light_sources)}")
        print(f"         Looking for gems where SAME base ID has ALL light sources: {sorted(goi_light_sources)}")
        
        # Group by base gem ID (extracted from full gem_id)
        base_gem_analysis = {}
        
        for gem_id, gem_data in db_df.groupby(file_col):
            # Extract base gem ID (e.g., "140" from "140BP2", "140LC1", "140UC1")
            base_id = self.extract_base_id(str(gem_id))
            
            if not base_id:
                continue
            
            # Determine light source for this specific record
            light_sources_for_this_record = set()
            for light_value in gem_data[light_col].unique():
                if str(light_value).strip() in ['B', 'Halogen', 'halogen']:
                    light_sources_for_this_record.add('B')
                elif str(light_value).strip() in ['L', 'Laser', 'laser']:
                    light_sources_for_this_record.add('L')
                elif str(light_value).strip() in ['U', 'UV', 'uv']:
                    light_sources_for_this_record.add('U')
            
            # Initialize base gem tracking
            if base_id not in base_gem_analysis:
                base_gem_analysis[base_id] = {
                    'light_sources': set(),
                    'gem_ids': [],
                    'records': []
                }
            
            # Add this gem's light sources to the base gem
            base_gem_analysis[base_id]['light_sources'].update(light_sources_for_this_record)
            base_gem_analysis[base_id]['gem_ids'].append(gem_id)
            base_gem_analysis[base_id]['records'].extend(gem_data.index.tolist())
        
        # Find valid base gems (have ALL required light sources)
        valid_base_gems = []
        valid_gem_ids = []
        
        for base_id, analysis in base_gem_analysis.items():
            gem_lights = analysis['light_sources']
            gem_ids = analysis['gem_ids']
            
            # Check if this base gem has ALL required light sources
            if gem_lights == goi_light_sources:
                valid_base_gems.append(base_id)
                valid_gem_ids.extend(gem_ids)
                
                print(f"         ‚úÖ Base Gem {base_id}: Has {sorted(gem_lights)} - VALID")
                print(f"            Database entries: {gem_ids}")
            else:
                missing = goi_light_sources - gem_lights
                extra = gem_lights - goi_light_sources
                status_parts = []
                if missing:
                    status_parts.append(f"missing: {sorted(missing)}")
                if extra:
                    status_parts.append(f"extra: {sorted(extra)}")
                status = f" ({', '.join(status_parts)})" if status_parts else ""
                print(f"         üö´ Base Gem {base_id}: Has {sorted(gem_lights)} - INVALID{status}")
                print(f"            Database entries: {gem_ids}")
        
        # Filter database to only valid gems
        filtered_db = db_df[db_df[file_col].isin(valid_gem_ids)]
        
        print(f"      üìä FILTERING RESULTS:")
        print(f"         Total database entries: {len(db_df)}")
        print(f"         Total unique base gems: {len(base_gem_analysis)}")
        print(f"         Valid base gems: {len(valid_base_gems)} ‚Üí {sorted(valid_base_gems)}")
        print(f"         Valid database entries: {len(valid_gem_ids)}")
        print(f"         Expected valid gems: 140, 194, 195, 196, 197, 199")
        print(f"         Filtered records: {len(filtered_db)}/{len(db_df)}")
        
        return filtered_db, valid_gem_ids
    
    def run_analysis(self):
        """üéØ MAIN: Run complete analysis with automatic valid gem detection"""
        print(f"\nüöÄ Starting automatic analysis of {len(self.selected_gems)} gems...")
        
        # Create output directories
        results_dir = self.project_root / "outputs" / "structural_results"
        reports_dir = results_dir / "reports"
        graphs_dir = results_dir / "graphs"
        
        for dir_path in [results_dir, reports_dir, graphs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Load database
        try:
            if self.database_type == "sqlite":
                conn = sqlite3.connect(self.database_path)
                query = f"SELECT * FROM {self.database_schema['table_name']}"
                db_df = pd.read_sql_query(query, conn)
                conn.close()
            else:
                db_df = pd.read_csv(self.database_path)
            
            print(f"‚úÖ Database loaded: {len(db_df):,} records")
        except Exception as e:
            print(f"‚ùå Database load failed: {e}")
            if self.mode == "gui":
                messagebox.showerror("Error", f"Database load failed: {e}")
            return False
        
        # üéØ NEW: Automatic GOI light source detection
        goi_light_sources = self.detect_goi_light_sources()
        
        # üéØ NEW: Automatic valid gem detection
        filtered_db, valid_gem_ids = self.find_valid_database_gems(db_df, goi_light_sources)
        
        if not valid_gem_ids:
            print(f"‚ùå No valid database gems found with matching light sources!")
            return False
        
        # Analyze each gem
        all_results = []
        
        for i, (base_id, data) in enumerate(self.selected_gems.items()):
            print(f"\nüéØ Analyzing Gem {base_id} ({i+1}/{len(self.selected_gems)})...")
            print(f"   üìä Comparing against {len(valid_gem_ids)} valid database gems")
            
            if self.mode == "gui":
                self.status_var.set(f"Analyzing Gem {base_id}...")
                self.root.update()
            
            gem_results = {
                'gem_id': base_id,
                'timestamp': timestamp,
                'goi_light_sources': sorted(goi_light_sources),
                'valid_database_gems': sorted([str(g) for g in valid_gem_ids]),
                'light_source_results': {},
                'best_match': None
            }
            
            # Analyze each light source
            for light_source, file_path in data['paths'].items():
                print(f"   üìÑ Processing {light_source}: {file_path.name}")
                
                try:
                    unknown_df = pd.read_csv(file_path)
                    if unknown_df.empty:
                        continue
                    
                    # Find database matches (now pre-filtered to valid gems only)
                    db_matches = self.find_database_matches(filtered_db, light_source)
                    if db_matches.empty:
                        continue
                    
                    # Calculate scores
                    scores = self.calculate_similarity_scores(unknown_df, db_matches, light_source, file_path)
                    
                    if scores:
                        best = min(scores, key=lambda x: x['score'])
                        print(f"      ‚úÖ Best: {best['db_gem_id']} (score: {best['score']:.6f})")
                        
                        # Check if this is a self-match
                        if self.is_self_match(base_id, best['db_gem_id']) and best['score'] < 0.01:
                            print(f"      üéØ PERFECT SELF-MATCH DETECTED!")
                        
                        gem_results['light_source_results'][light_source] = {
                            'file': file_path.name,
                            'best_match': best,
                            'top_5': sorted(scores, key=lambda x: x['score'])[:5]
                        }
                
                except Exception as e:
                    print(f"      ‚ùå Error: {e}")
                    continue
            
            # Calculate combined scores
            if len(gem_results['light_source_results']) > 1:
                combined = self.calculate_combined_scores(gem_results['light_source_results'])
                if combined:
                    best_combined = min(combined, key=lambda x: x['score'])
                    gem_results['best_match'] = best_combined
                    
                    # Check if best overall match is self-match
                    if self.is_self_match(base_id, best_combined['db_gem_id']):
                        if best_combined.get('percentage', 0) > 95:
                            print(f"   üéØ EXCELLENT: Perfect self-match achieved ({best_combined.get('percentage', 0):.2f}%)")
                        else:
                            print(f"   ‚ö†Ô∏è CONCERN: Self-match but lower score ({best_combined.get('percentage', 0):.2f}%)")
                    
                    print(f"   üèÜ Best combined: {best_combined['db_gem_id']} (score: {best_combined['score']:.4f})")
            
            all_results.append(gem_results)
        
        # Save results
        self.save_results(all_results, reports_dir, timestamp)
        
        # Generate visualizations
        if HAS_MATPLOTLIB:
            self.generate_plots(all_results, graphs_dir, timestamp)
        
        print(f"\nüéâ Analysis complete! Results in: {results_dir}")
        
        if self.mode == "gui":
            messagebox.showinfo("Complete", f"Analysis complete!\nResults saved to: {results_dir}")
            self.status_var.set("Analysis complete")
        
        return True
    
    def is_self_match(self, goi_id, db_gem_id):
        """üéØ ENHANCED: Check if this is a self-match with better gem ID comparison"""
        goi_base = str(goi_id).strip()
        db_base = self.extract_base_id(str(db_gem_id))
        return goi_base == db_base
    
    def is_detailed_self_match(self, goi_filename, db_gem_id):
        """üéØ NEW: Detailed self-match detection for GOI filename vs database gem ID"""
        
        # Extract detailed gem identifier from GOI filename
        goi_gem_identifier = self.extract_detailed_gem_identifier(goi_filename)
        
        # Extract detailed gem identifier from database gem ID  
        db_gem_identifier = self.extract_detailed_gem_identifier(str(db_gem_id))
        
        print(f"         üîç Self-match check:")
        print(f"             GOI: '{goi_filename}' ‚Üí identifier: '{goi_gem_identifier}'")
        print(f"             DB:  '{db_gem_id}' ‚Üí identifier: '{db_gem_identifier}'")
        
        # Check if they match
        if goi_gem_identifier and db_gem_identifier:
            is_match = goi_gem_identifier == db_gem_identifier
            print(f"             Match: {is_match}")
            return is_match
        
        # Fallback to base ID matching
        goi_base = self.extract_base_id(goi_filename)
        db_base = self.extract_base_id(str(db_gem_id))
        fallback_match = goi_base == db_base
        print(f"             Fallback base ID match: {fallback_match} ({goi_base} vs {db_base})")
        return fallback_match
    
    def extract_detailed_gem_identifier(self, filename_or_id):
        """üéØ NEW: Extract detailed gem identifier (e.g., '197BC3' from various formats)"""
        
        # Remove file extensions and timestamps
        identifier = str(filename_or_id).strip()
        identifier = re.sub(r'\.csv
    
    def find_database_matches(self, filtered_db, light_source):
        """Find database matches (already filtered to valid gems)"""
        light_col = self.database_schema.get('light_column')
        
        if light_col and light_col in filtered_db.columns:
            light_mapping = {'B': ['B', 'Halogen', 'halogen'], 
                           'L': ['L', 'Laser', 'laser'], 
                           'U': ['U', 'UV', 'uv']}
            
            light_values = light_mapping.get(light_source, [light_source])
            matches = filtered_db[filtered_db[light_col].isin(light_values)]
        else:
            matches = filtered_db.copy()
        
        # Add date extraction
        file_col = self.database_schema['file_column']
        if file_col in matches.columns:
            matches['extracted_date'] = matches[file_col].apply(self.extract_date_from_filename)
        
        return matches
    
    def calculate_similarity_scores(self, unknown_df, db_matches, light_source, file_path):
        """Calculate similarity with perfect self-match detection"""
        scores = []
        
        file_col = self.database_schema['file_column']
        wl_col = self.database_schema['wavelength_column']
        int_col = self.database_schema['intensity_column']
        
        if not all([file_col, wl_col, int_col]):
            return scores
        
        # Detect unknown data columns
        unknown_wl_col, unknown_int_col = self.detect_unknown_columns(unknown_df)
        if not unknown_wl_col or not unknown_int_col:
            return scores
        
        try:
            unknown_wl = unknown_df[unknown_wl_col].values
            unknown_int = unknown_df[unknown_int_col].values
            
            # Remove NaN
            valid = ~(np.isnan(unknown_wl) | np.isnan(unknown_int))
            unknown_wl = unknown_wl[valid]
            unknown_int = unknown_int[valid]
            
            if len(unknown_wl) < 3:
                return scores
        except:
            return scores
        
        # Extract GOI base ID for self-match detection
        goi_base_id = self.extract_base_id(file_path.name)
        
        # Group database by gem
        for gem_id, gem_data in db_matches.groupby(file_col):
            try:
                if len(gem_data) < 1:
                    continue
                
                # Extract database gem base ID
                db_base_id = self.extract_base_id(str(gem_id))
                
                # Get date info
                dates = gem_data.get('extracted_date', pd.Series([None])).dropna().unique()
                gem_date = dates[0] if len(dates) > 0 else None
                
                db_wl = gem_data[wl_col].values
                db_int = gem_data[int_col].values
                
                # Remove NaN
                db_valid = ~(np.isnan(db_wl) | np.isnan(db_int))
                db_wl = db_wl[db_valid]
                db_int = db_int[db_valid]
                
                if len(db_wl) < 1:
                    continue
                
                # üéØ CRITICAL: Self-match detection
                if goi_base_id and db_base_id and goi_base_id == db_base_id:
                    score = self.compute_perfect_match_score(unknown_wl, unknown_int, db_wl, db_int)
                    if score is not None:
                        print(f"         üéØ PERFECT SELF-MATCH: {file_path.name} ‚Üî {gem_id} (score: {score:.6f})")
                        scores.append({
                            'db_gem_id': gem_id,
                            'score': score,
                            'date': gem_date,
                            'is_perfect': True
                        })
                        continue
                
                # Normal similarity calculation
                score = self.compute_similarity(unknown_wl, unknown_int, db_wl, db_int)
                
                if score is not None and not math.isnan(score):
                    scores.append({
                        'db_gem_id': gem_id,
                        'score': score,
                        'date': gem_date,
                        'is_perfect': False
                    })
            
            except Exception as e:
                continue
        
        return scores
    
    def extract_base_id(self, filename):
        """Extract numeric base ID from filename"""
        # Remove extensions and suffixes
        stem = re.sub(r'\.csv$', '', filename)
        stem = re.sub(r'_(structural|halogen|laser|uv|TS\d+|\d{8}_\d{6}).*$', '', stem)
        
        # Extract leading digits
        match = re.search(r'^[A-Za-z]*(\d+)', stem)
        return match.group(1) if match else None
    
    def detect_unknown_columns(self, df):
        """Detect wavelength and intensity columns"""
        wl_col = int_col = None
        
        for col in df.columns:
            col_lower = col.lower()
            if 'wavelength' in col_lower or col_lower == 'wl':
                wl_col = col
            elif 'intensity' in col_lower or 'value' in col_lower:
                int_col = col
        
        # Fallback to structural format
        if not wl_col and 'Wavelength' in df.columns:
            wl_col = 'Wavelength'
        if not int_col and 'Intensity' in df.columns:
            int_col = 'Intensity'
        elif not int_col and 'Value' in df.columns:
            int_col = 'Value'
        
        # Final fallback: numeric columns
        if not wl_col or not int_col:
            numeric = df.select_dtypes(include=[np.number]).columns.tolist()
            if len(numeric) >= 2:
                wl_col = wl_col or numeric[0]
                int_col = int_col or numeric[1]
        
        return wl_col, int_col
    
    def compute_perfect_match_score(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute perfect match score for identical data"""
        try:
            # Quick similarity checks
            size_ratio = min(len(unknown_wl), len(db_wl)) / max(len(unknown_wl), len(db_wl))
            if size_ratio < 0.7:
                return None
            
            # Range similarity
            unknown_range = (np.min(unknown_wl), np.max(unknown_wl))
            db_range = (np.min(db_wl), np.max(db_wl))
            range_diff = abs(unknown_range[0] - db_range[0]) + abs(unknown_range[1] - db_range[1])
            
            if range_diff > 100.0:
                return None
            
            # Intensity similarity
            unknown_mean = np.mean(unknown_int)
            db_mean = np.mean(db_int)
            
            if max(unknown_mean, db_mean) > 0:
                mean_ratio = abs(unknown_mean - db_mean) / max(unknown_mean, db_mean)
                if mean_ratio > 0.8:
                    return None
            
            # Sample comparison
            sample_size = min(10, len(unknown_wl), len(db_wl))
            unknown_idx = np.linspace(0, len(unknown_wl)-1, sample_size, dtype=int)
            db_idx = np.linspace(0, len(db_wl)-1, sample_size, dtype=int)
            
            total_diff = 0.0
            for u_i, d_i in zip(unknown_idx, db_idx):
                wl_diff = abs(unknown_wl[u_i] - db_wl[d_i])
                max_int = max(unknown_int[u_i], db_int[d_i])
                int_diff = abs(unknown_int[u_i] - db_int[d_i]) / max_int if max_int > 0 else 0
                total_diff += (wl_diff * 0.01 + int_diff)
            
            avg_diff = total_diff / sample_size
            
            # Perfect match criteria
            if avg_diff < 0.4 and size_ratio > 0.8 and range_diff < 50.0:
                return 0.001 + avg_diff * 0.01  # 0.001-0.005 range
            
            return None
            
        except:
            return None
    
    def compute_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute normal similarity score"""
        try:
            # Check for UV data (811nm)
            has_uv = (np.any((unknown_wl >= 800) & (unknown_wl <= 900)) or 
                     np.any((db_wl >= 800) & (db_wl <= 900)))
            
            if has_uv or any(abs(wl - 811.0) < 5 for wl in unknown_wl):
                return self.compute_uv_similarity(unknown_wl, unknown_int, db_wl, db_int)
            else:
                return self.compute_structural_similarity(unknown_wl, unknown_int, db_wl, db_int)
        except:
            return None
    
    def compute_uv_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """UV-specific similarity (811nm normalization)"""
        try:
            # Find 811nm reference
            unknown_811 = self.find_811nm_intensity(unknown_wl, unknown_int)
            db_811 = self.find_811nm_intensity(db_wl, db_int)
            
            if not unknown_811 or not db_811:
                return None
            
            # Calculate ratios
            unknown_ratios = {float(wl): float(intensity / unknown_811) 
                            for wl, intensity in zip(unknown_wl, unknown_int) if intensity > 0}
            db_ratios = {float(wl): float(intensity / db_811) 
                        for wl, intensity in zip(db_wl, db_int) if intensity > 0}
            
            # Compare ratios
            matched = 0
            total_diff = 0.0
            
            for u_wl, u_ratio in unknown_ratios.items():
                best_match = None
                best_distance = float('inf')
                
                for d_wl, d_ratio in db_ratios.items():
                    distance = abs(u_wl - d_wl)
                    if distance <= 5.0 and distance < best_distance:
                        best_distance = distance
                        best_match = d_ratio
                
                if best_match is not None:
                    ratio_diff = abs(u_ratio - best_match) / max(u_ratio, best_match)
                    total_diff += ratio_diff
                    matched += 1
            
            if matched > 0:
                avg_diff = total_diff / matched
                coverage = matched / len(unknown_ratios)
                return avg_diff * (2.0 - coverage)  # Penalty for poor coverage
            
            return None
            
        except:
            return None
    
    def find_811nm_intensity(self, wavelengths, intensities):
        """Find 811nm reference intensity"""
        # Look for exact match
        exact = np.abs(wavelengths - 811.0) < 0.5
        if np.any(exact):
            return intensities[exact][0]
        
        # Look within tolerance
        tolerance = np.abs(wavelengths - 811.0) <= 5.0
        if np.any(tolerance):
            nearby_wl = wavelengths[tolerance]
            nearby_int = intensities[tolerance]
            return np.interp(811.0, nearby_wl, nearby_int)
        
        # Use proxy (highest in 800-850nm range)
        proxy = (wavelengths >= 800) & (wavelengths <= 850)
        if np.any(proxy):
            return np.max(intensities[proxy])
        
        return None
    
    def compute_structural_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Structural similarity for B/L light sources"""
        try:
            total_score = 0.0
            matched = 0
            tolerance = 10.0
            
            unique_wl = np.unique(unknown_wl)
            
            for u_wl in unique_wl:
                distances = np.abs(db_wl - u_wl)
                nearby = distances <= tolerance
                
                if np.any(nearby):
                    u_int = unknown_int[np.abs(unknown_wl - u_wl) < 0.1]
                    d_int = db_int[nearby]
                    
                    if len(u_int) > 0 and len(d_int) > 0:
                        u_avg = np.mean(u_int)
                        d_avg = np.mean(d_int)
                        
                        if max(u_avg, d_avg) > 0:
                            diff = abs(u_avg - d_avg) / max(u_avg, d_avg)
                            weight = 1.0 - (np.min(distances[nearby]) / tolerance)
                            total_score += diff * weight
                            matched += 1
                else:
                    total_score += 2.0  # Penalty for no match
            
            if len(unique_wl) > 0:
                avg_score = total_score / len(unique_wl)
                match_rate = matched / len(unique_wl)
                return avg_score * (1.2 - match_rate * 0.2)
            
            return None
            
        except:
            return None
    
    def calculate_combined_scores(self, light_source_results):
        """Calculate combined scores with DATE consistency"""
        gem_combinations = {}
        
        # Collect all combinations
        for ls, ls_data in light_source_results.items():
            for match in ls_data['top_5']:
                gem_id = match['db_gem_id']
                gem_date = match.get('date')
                
                if gem_id not in gem_combinations:
                    gem_combinations[gem_id] = {}
                
                gem_combinations[gem_id][ls] = {
                    'score': match['score'],
                    'percentage': self.score_to_percentage(match['score']),
                    'date': gem_date,
                    'is_perfect': match.get('is_perfect', False)
                }
        
        # Check date consistency
        valid_combinations = []
        
        for gem_id, light_data in gem_combinations.items():
            # Get all dates for this gem
            dates = set()
            for ls_info in light_data.values():
                if ls_info['date']:
                    dates.add(ls_info['date'])
            
            # Only allow same-date combinations
            if len(dates) <= 1:  # All same date or no dates
                light_scores = {}
                perfect_count = 0
                
                for ls, ls_info in light_data.items():
                    light_scores[ls] = ls_info['percentage']
                    if ls_info['is_perfect']:
                        perfect_count += 1
                
                if light_scores:
                    # Weighted average
                    weights = {'B': 1.0, 'L': 0.9, 'U': 0.8}
                    weighted_sum = sum(score * weights.get(ls, 1.0) for ls, score in light_scores.items())
                    total_weight = sum(weights.get(ls, 1.0) for ls in light_scores.keys())
                    
                    avg_percentage = weighted_sum / total_weight
                    
                    # Bonuses
                    completeness = 1.0 if len(light_scores) == 3 else 0.8
                    perfect_bonus = 1.0 + perfect_count * 0.05
                    
                    final_percentage = avg_percentage * completeness * perfect_bonus
                    final_percentage = min(100.0, final_percentage)
                    
                    # Convert back to score (lower is better)
                    combined_score = max(0.0, (100.0 - final_percentage) / 25.0)
                    
                    valid_combinations.append({
                        'db_gem_id': gem_id,
                        'score': combined_score,
                        'percentage': final_percentage,
                        'light_sources': list(light_scores.keys()),
                        'date': list(dates)[0] if dates else None,
                        'perfect_count': perfect_count,
                        'date_consistent': True
                    })
        
        return valid_combinations
    
    def score_to_percentage(self, score):
        """Convert score to percentage"""
        if score is None:
            return 0.0
        
        if score <= self.perfect_match_threshold:
            # Perfect: 98-100%
            ratio = score / self.perfect_match_threshold
            return 100.0 - ratio * 2.0
        
        # Normal: exponential decay
        return max(0.0, min(98.0, 98.0 * np.exp(-score * 3.0)))
    
    def save_results(self, all_results, reports_dir, timestamp):
        """Save analysis results"""
        # Summary CSV
        summary_data = []
        for result in all_results:
            row = {
                'Gem_ID': result['gem_id'],
                'Timestamp': timestamp,
                'GOI_Light_Sources': '+'.join(result['goi_light_sources']),
                'Valid_Database_Gems': '+'.join(result['valid_database_gems']),
                'Light_Sources_Analyzed': '+'.join(result['light_source_results'].keys()),
                'Source_Count': len(result['light_source_results'])
            }
            
            if result['best_match']:
                match = result['best_match']
                row.update({
                    'Best_Match': match['db_gem_id'],
                    'Score': match['score'],
                    'Percentage': match.get('percentage', 0),
                    'Date_Consistent': match.get('date_consistent', False),
                    'Perfect_Count': match.get('perfect_count', 0)
                })
            
            summary_data.append(row)
        
        if summary_data:
            df = pd.DataFrame(summary_data)
            summary_file = reports_dir / f"structural_analysis_{timestamp}.csv"
            df.to_csv(summary_file, index=False)
            print(f"üìÑ Summary saved: {summary_file.name}")
        
        # Full results JSON
        json_file = reports_dir / f"structural_analysis_full_{timestamp}.json"
        with open(json_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        print(f"üìÑ Full results saved: {json_file.name}")
        
        # Formatted report
        self.generate_formatted_report(all_results, reports_dir, timestamp)
    
    def generate_formatted_report(self, all_results, reports_dir, timestamp):
        """Generate formatted text report"""
        if not all_results:
            return
        
        # Find best result
        best_result = None
        best_score = float('inf')
        
        for result in all_results:
            if result['best_match'] and result['best_match']['score'] < best_score:
                best_score = result['best_match']['score']
                best_result = result
        
        if not best_result:
            return
        
        goi_id = best_result['gem_id']
        goi_desc = self.gem_name_map.get(str(goi_id), f"Unknown Gem {goi_id}")
        
        # Generate report
        report = f"""GEMINI STRUCTURAL ANALYSIS RESULTS (AUTOMATIC VALID GEM DETECTION)
Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Analyzer: Multi-Gem with Automatic Valid Gem Detection
Source: {self.input_source}

Analyzed Gem (GOI): {goi_id}
GOI Description: {goi_desc}
GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}
Valid Database Gems: {'+'.join(best_result['valid_database_gems'])}
{'='*80}

ENHANCED FEATURES:
‚úÖ Automatic GOI Light Source Detection
‚úÖ Automatic Valid Database Gem Detection  
‚úÖ Date-Based TS Matching (Same Day Consistency)
‚úÖ Perfect Self-Matching (100% for identical files)
‚úÖ Enhanced Result Formatting

TOP MATCH:
"""
        
        top_match = best_result['best_match']
        top_id = top_match['db_gem_id']
        top_desc = self.gem_name_map.get(str(top_id), f"Unknown Gem {top_id}")
        
        report += f"""Database Gem ID: {top_id}
Description: {top_desc}
Combined Score: {top_match['score']:.4f}
Combined Percentage: {top_match.get('percentage', 0):.2f}%
Light Sources: {', '.join(top_match['light_sources'])} ({len(top_match['light_sources'])})
Date Consistent: {top_match.get('date_consistent', False)}
Perfect Matches: {top_match.get('perfect_count', 0)}

"""
        
        # Self-match analysis
        is_self_match = self.is_self_match(goi_id, top_id)
        if is_self_match:
            if top_match.get('percentage', 0) > 95:
                report += "üéØ EXCELLENT: Perfect self-match achieved!\n\n"
            else:
                report += "‚ö†Ô∏è CONCERN: Self-match detected but score lower than expected\n\n"
        else:
            report += f"üìä Valid cross-match with gem {top_id}\n\n"
        
        # Save report
        report_file = reports_dir / f"structural_summary_gem_{goi_id}_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìÑ Formatted report saved: {report_file.name}")
        print(f"\nüéØ ANALYSIS SUMMARY:")
        print(f"   GOI: {goi_id} ({goi_desc})")
        print(f"   GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}")
        print(f"   Valid Database Gems: {len(best_result['valid_database_gems'])}")
        print(f"   Best Match: {top_id} ({top_desc})")
        print(f"   Score: {top_match['score']:.4f} ({top_match.get('percentage', 0):.2f}%)")
        if is_self_match:
            print(f"   üéØ Self-Match: {'‚úÖ Perfect' if top_match.get('percentage', 0) > 95 else '‚ö†Ô∏è Suboptimal'}")
    
    def generate_plots(self, all_results, graphs_dir, timestamp):
        """Generate summary plots"""
        if not HAS_MATPLOTLIB:
            return
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle('Structural Analysis with Automatic Valid Gem Detection', fontsize=14, fontweight='bold')
            
            # Plot 1: Scores
            scores = []
            perfect_flags = []
            for result in all_results:
                if result['best_match']:
                    scores.append(result['best_match']['score'])
                    perfect_flags.append(result['best_match'].get('perfect_count', 0) > 0)
            
            if scores:
                colors = ['red' if perfect else 'skyblue' for perfect in perfect_flags]
                axes[0, 0].bar(range(len(scores)), scores, color=colors)
                axes[0, 0].set_title('Match Scores (Red = Perfect Self-Match)')
                axes[0, 0].set_ylabel('Score')
                axes[0, 0].grid(True, alpha=0.3)
            
            # Plot 2: Valid gems count
            valid_counts = []
            for result in all_results:
                valid_counts.append(len(result['valid_database_gems']))
            
            if valid_counts:
                axes[0, 1].bar(['Valid Database Gems'], [valid_counts[0]])
                axes[0, 1].set_title('Automatically Detected Valid Gems')
                axes[0, 1].set_ylabel('Count')
                axes[0, 1].grid(True, alpha=0.3)
            
            # Plot 3: Percentage distribution
            percentages = []
            for result in all_results:
                if result['best_match']:
                    percentages.append(result['best_match'].get('percentage', 0))
            
            if percentages:
                axes[1, 0].hist(percentages, bins=15, color='lightgreen', edgecolor='black', alpha=0.7)
                axes[1, 0].set_title('Match Percentage Distribution')
                axes[1, 0].set_xlabel('Percentage (%)')
                axes[1, 0].set_ylabel('Frequency')
                axes[1, 0].grid(True, alpha=0.3)
            
            # Plot 4: Self-match indicator
            perfect_count = sum(perfect_flags) if scores else 0
            normal_count = len(scores) - perfect_count if scores else 0
            
            if perfect_count > 0 or normal_count > 0:
                axes[1, 1].pie([perfect_count, normal_count], 
                             labels=['Perfect Self-Match', 'Normal Match'],
                             colors=['red', 'lightblue'],
                             autopct='%1.1f%%')
                axes[1, 1].set_title('Perfect vs Normal Matches')
            
            plt.tight_layout()
            
            plot_file = graphs_dir / f"analysis_summary_{timestamp}.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìà Summary plot saved: {plot_file.name}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Plot generation failed: {e}")
    
    def run_auto_analysis(self, auto_select_complete=True):
        """Run automatic analysis"""
        print(f"ü§ñ Auto analysis: {self.input_source} source")
        print(f"üéØ Features: Automatic valid gem detection, perfect self-match")
        
        if not self.gem_groups or not self.database_schema:
            print("‚ùå No gems or database not available")
            return False
        
        # Auto-select complete gems
        if auto_select_complete:
            for base_id, data in self.gem_groups.items():
                if all(len(data['files'][ls]) > 0 for ls in ['B', 'L', 'U']):
                    selected = {'files': {}, 'paths': {}}
                    for ls in ['B', 'L', 'U']:
                        selected['files'][ls] = data['files'][ls][0]
                        selected['paths'][ls] = data['paths'][ls][0]
                    self.selected_gems[base_id] = selected
        
        if not self.selected_gems:
            print("‚ùå No complete gems found")
            return False
        
        print(f"‚úÖ Auto-selected {len(self.selected_gems)} complete gems")
        return self.run_analysis()
    
    def run(self):
        """Start GUI"""
        if self.mode == "gui" and self.root:
            self.root.mainloop()

def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
    parser.add_argument("--mode", choices=["gui", "auto"], default="gui")
    parser.add_argument("--input-source", choices=["archive", "current"], default="archive")
    parser.add_argument("--auto-complete", action="store_true", default=True)
    
    args = parser.parse_args()
    
    try:
        print("üöÄ Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
        print(f"   Mode: {args.mode}, Source: {args.input_source}")
        print("   Features: Auto Light Source Detection, Auto Valid Gem Filtering, Perfect Self-Match")
        
        analyzer = MultiGemStructuralAnalyzer(mode=args.mode, input_source=args.input_source)
        
        if args.mode == "gui":
            analyzer.run()
        else:
            success = analyzer.run_auto_analysis(args.auto_complete)
            return success
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()
, '', identifier)
        identifier = re.sub(r'_\d{8}_\d{6}.*
    
    def find_database_matches(self, filtered_db, light_source):
        """Find database matches (already filtered to valid gems)"""
        light_col = self.database_schema.get('light_column')
        
        if light_col and light_col in filtered_db.columns:
            light_mapping = {'B': ['B', 'Halogen', 'halogen'], 
                           'L': ['L', 'Laser', 'laser'], 
                           'U': ['U', 'UV', 'uv']}
            
            light_values = light_mapping.get(light_source, [light_source])
            matches = filtered_db[filtered_db[light_col].isin(light_values)]
        else:
            matches = filtered_db.copy()
        
        # Add date extraction
        file_col = self.database_schema['file_column']
        if file_col in matches.columns:
            matches['extracted_date'] = matches[file_col].apply(self.extract_date_from_filename)
        
        return matches
    
    def calculate_similarity_scores(self, unknown_df, db_matches, light_source, file_path):
        """Calculate similarity with perfect self-match detection"""
        scores = []
        
        file_col = self.database_schema['file_column']
        wl_col = self.database_schema['wavelength_column']
        int_col = self.database_schema['intensity_column']
        
        if not all([file_col, wl_col, int_col]):
            return scores
        
        # Detect unknown data columns
        unknown_wl_col, unknown_int_col = self.detect_unknown_columns(unknown_df)
        if not unknown_wl_col or not unknown_int_col:
            return scores
        
        try:
            unknown_wl = unknown_df[unknown_wl_col].values
            unknown_int = unknown_df[unknown_int_col].values
            
            # Remove NaN
            valid = ~(np.isnan(unknown_wl) | np.isnan(unknown_int))
            unknown_wl = unknown_wl[valid]
            unknown_int = unknown_int[valid]
            
            if len(unknown_wl) < 3:
                return scores
        except:
            return scores
        
        # Extract GOI base ID for self-match detection
        goi_base_id = self.extract_base_id(file_path.name)
        
        # Group database by gem
        for gem_id, gem_data in db_matches.groupby(file_col):
            try:
                if len(gem_data) < 1:
                    continue
                
                # Extract database gem base ID
                db_base_id = self.extract_base_id(str(gem_id))
                
                # Get date info
                dates = gem_data.get('extracted_date', pd.Series([None])).dropna().unique()
                gem_date = dates[0] if len(dates) > 0 else None
                
                db_wl = gem_data[wl_col].values
                db_int = gem_data[int_col].values
                
                # Remove NaN
                db_valid = ~(np.isnan(db_wl) | np.isnan(db_int))
                db_wl = db_wl[db_valid]
                db_int = db_int[db_valid]
                
                if len(db_wl) < 1:
                    continue
                
                # üéØ CRITICAL: Self-match detection
                if goi_base_id and db_base_id and goi_base_id == db_base_id:
                    score = self.compute_perfect_match_score(unknown_wl, unknown_int, db_wl, db_int)
                    if score is not None:
                        print(f"         üéØ PERFECT SELF-MATCH: {file_path.name} ‚Üî {gem_id} (score: {score:.6f})")
                        scores.append({
                            'db_gem_id': gem_id,
                            'score': score,
                            'date': gem_date,
                            'is_perfect': True
                        })
                        continue
                
                # Normal similarity calculation
                score = self.compute_similarity(unknown_wl, unknown_int, db_wl, db_int)
                
                if score is not None and not math.isnan(score):
                    scores.append({
                        'db_gem_id': gem_id,
                        'score': score,
                        'date': gem_date,
                        'is_perfect': False
                    })
            
            except Exception as e:
                continue
        
        return scores
    
    def extract_base_id(self, filename):
        """Extract numeric base ID from filename"""
        # Remove extensions and suffixes
        stem = re.sub(r'\.csv$', '', filename)
        stem = re.sub(r'_(structural|halogen|laser|uv|TS\d+|\d{8}_\d{6}).*$', '', stem)
        
        # Extract leading digits
        match = re.search(r'^[A-Za-z]*(\d+)', stem)
        return match.group(1) if match else None
    
    def detect_unknown_columns(self, df):
        """Detect wavelength and intensity columns"""
        wl_col = int_col = None
        
        for col in df.columns:
            col_lower = col.lower()
            if 'wavelength' in col_lower or col_lower == 'wl':
                wl_col = col
            elif 'intensity' in col_lower or 'value' in col_lower:
                int_col = col
        
        # Fallback to structural format
        if not wl_col and 'Wavelength' in df.columns:
            wl_col = 'Wavelength'
        if not int_col and 'Intensity' in df.columns:
            int_col = 'Intensity'
        elif not int_col and 'Value' in df.columns:
            int_col = 'Value'
        
        # Final fallback: numeric columns
        if not wl_col or not int_col:
            numeric = df.select_dtypes(include=[np.number]).columns.tolist()
            if len(numeric) >= 2:
                wl_col = wl_col or numeric[0]
                int_col = int_col or numeric[1]
        
        return wl_col, int_col
    
    def compute_perfect_match_score(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute perfect match score for identical data"""
        try:
            # Quick similarity checks
            size_ratio = min(len(unknown_wl), len(db_wl)) / max(len(unknown_wl), len(db_wl))
            if size_ratio < 0.7:
                return None
            
            # Range similarity
            unknown_range = (np.min(unknown_wl), np.max(unknown_wl))
            db_range = (np.min(db_wl), np.max(db_wl))
            range_diff = abs(unknown_range[0] - db_range[0]) + abs(unknown_range[1] - db_range[1])
            
            if range_diff > 100.0:
                return None
            
            # Intensity similarity
            unknown_mean = np.mean(unknown_int)
            db_mean = np.mean(db_int)
            
            if max(unknown_mean, db_mean) > 0:
                mean_ratio = abs(unknown_mean - db_mean) / max(unknown_mean, db_mean)
                if mean_ratio > 0.8:
                    return None
            
            # Sample comparison
            sample_size = min(10, len(unknown_wl), len(db_wl))
            unknown_idx = np.linspace(0, len(unknown_wl)-1, sample_size, dtype=int)
            db_idx = np.linspace(0, len(db_wl)-1, sample_size, dtype=int)
            
            total_diff = 0.0
            for u_i, d_i in zip(unknown_idx, db_idx):
                wl_diff = abs(unknown_wl[u_i] - db_wl[d_i])
                max_int = max(unknown_int[u_i], db_int[d_i])
                int_diff = abs(unknown_int[u_i] - db_int[d_i]) / max_int if max_int > 0 else 0
                total_diff += (wl_diff * 0.01 + int_diff)
            
            avg_diff = total_diff / sample_size
            
            # Perfect match criteria
            if avg_diff < 0.4 and size_ratio > 0.8 and range_diff < 50.0:
                return 0.001 + avg_diff * 0.01  # 0.001-0.005 range
            
            return None
            
        except:
            return None
    
    def compute_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute normal similarity score"""
        try:
            # Check for UV data (811nm)
            has_uv = (np.any((unknown_wl >= 800) & (unknown_wl <= 900)) or 
                     np.any((db_wl >= 800) & (db_wl <= 900)))
            
            if has_uv or any(abs(wl - 811.0) < 5 for wl in unknown_wl):
                return self.compute_uv_similarity(unknown_wl, unknown_int, db_wl, db_int)
            else:
                return self.compute_structural_similarity(unknown_wl, unknown_int, db_wl, db_int)
        except:
            return None
    
    def compute_uv_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """UV-specific similarity (811nm normalization)"""
        try:
            # Find 811nm reference
            unknown_811 = self.find_811nm_intensity(unknown_wl, unknown_int)
            db_811 = self.find_811nm_intensity(db_wl, db_int)
            
            if not unknown_811 or not db_811:
                return None
            
            # Calculate ratios
            unknown_ratios = {float(wl): float(intensity / unknown_811) 
                            for wl, intensity in zip(unknown_wl, unknown_int) if intensity > 0}
            db_ratios = {float(wl): float(intensity / db_811) 
                        for wl, intensity in zip(db_wl, db_int) if intensity > 0}
            
            # Compare ratios
            matched = 0
            total_diff = 0.0
            
            for u_wl, u_ratio in unknown_ratios.items():
                best_match = None
                best_distance = float('inf')
                
                for d_wl, d_ratio in db_ratios.items():
                    distance = abs(u_wl - d_wl)
                    if distance <= 5.0 and distance < best_distance:
                        best_distance = distance
                        best_match = d_ratio
                
                if best_match is not None:
                    ratio_diff = abs(u_ratio - best_match) / max(u_ratio, best_match)
                    total_diff += ratio_diff
                    matched += 1
            
            if matched > 0:
                avg_diff = total_diff / matched
                coverage = matched / len(unknown_ratios)
                return avg_diff * (2.0 - coverage)  # Penalty for poor coverage
            
            return None
            
        except:
            return None
    
    def find_811nm_intensity(self, wavelengths, intensities):
        """Find 811nm reference intensity"""
        # Look for exact match
        exact = np.abs(wavelengths - 811.0) < 0.5
        if np.any(exact):
            return intensities[exact][0]
        
        # Look within tolerance
        tolerance = np.abs(wavelengths - 811.0) <= 5.0
        if np.any(tolerance):
            nearby_wl = wavelengths[tolerance]
            nearby_int = intensities[tolerance]
            return np.interp(811.0, nearby_wl, nearby_int)
        
        # Use proxy (highest in 800-850nm range)
        proxy = (wavelengths >= 800) & (wavelengths <= 850)
        if np.any(proxy):
            return np.max(intensities[proxy])
        
        return None
    
    def compute_structural_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Structural similarity for B/L light sources"""
        try:
            total_score = 0.0
            matched = 0
            tolerance = 10.0
            
            unique_wl = np.unique(unknown_wl)
            
            for u_wl in unique_wl:
                distances = np.abs(db_wl - u_wl)
                nearby = distances <= tolerance
                
                if np.any(nearby):
                    u_int = unknown_int[np.abs(unknown_wl - u_wl) < 0.1]
                    d_int = db_int[nearby]
                    
                    if len(u_int) > 0 and len(d_int) > 0:
                        u_avg = np.mean(u_int)
                        d_avg = np.mean(d_int)
                        
                        if max(u_avg, d_avg) > 0:
                            diff = abs(u_avg - d_avg) / max(u_avg, d_avg)
                            weight = 1.0 - (np.min(distances[nearby]) / tolerance)
                            total_score += diff * weight
                            matched += 1
                else:
                    total_score += 2.0  # Penalty for no match
            
            if len(unique_wl) > 0:
                avg_score = total_score / len(unique_wl)
                match_rate = matched / len(unique_wl)
                return avg_score * (1.2 - match_rate * 0.2)
            
            return None
            
        except:
            return None
    
    def calculate_combined_scores(self, light_source_results):
        """Calculate combined scores with DATE consistency"""
        gem_combinations = {}
        
        # Collect all combinations
        for ls, ls_data in light_source_results.items():
            for match in ls_data['top_5']:
                gem_id = match['db_gem_id']
                gem_date = match.get('date')
                
                if gem_id not in gem_combinations:
                    gem_combinations[gem_id] = {}
                
                gem_combinations[gem_id][ls] = {
                    'score': match['score'],
                    'percentage': self.score_to_percentage(match['score']),
                    'date': gem_date,
                    'is_perfect': match.get('is_perfect', False)
                }
        
        # Check date consistency
        valid_combinations = []
        
        for gem_id, light_data in gem_combinations.items():
            # Get all dates for this gem
            dates = set()
            for ls_info in light_data.values():
                if ls_info['date']:
                    dates.add(ls_info['date'])
            
            # Only allow same-date combinations
            if len(dates) <= 1:  # All same date or no dates
                light_scores = {}
                perfect_count = 0
                
                for ls, ls_info in light_data.items():
                    light_scores[ls] = ls_info['percentage']
                    if ls_info['is_perfect']:
                        perfect_count += 1
                
                if light_scores:
                    # Weighted average
                    weights = {'B': 1.0, 'L': 0.9, 'U': 0.8}
                    weighted_sum = sum(score * weights.get(ls, 1.0) for ls, score in light_scores.items())
                    total_weight = sum(weights.get(ls, 1.0) for ls in light_scores.keys())
                    
                    avg_percentage = weighted_sum / total_weight
                    
                    # Bonuses
                    completeness = 1.0 if len(light_scores) == 3 else 0.8
                    perfect_bonus = 1.0 + perfect_count * 0.05
                    
                    final_percentage = avg_percentage * completeness * perfect_bonus
                    final_percentage = min(100.0, final_percentage)
                    
                    # Convert back to score (lower is better)
                    combined_score = max(0.0, (100.0 - final_percentage) / 25.0)
                    
                    valid_combinations.append({
                        'db_gem_id': gem_id,
                        'score': combined_score,
                        'percentage': final_percentage,
                        'light_sources': list(light_scores.keys()),
                        'date': list(dates)[0] if dates else None,
                        'perfect_count': perfect_count,
                        'date_consistent': True
                    })
        
        return valid_combinations
    
    def score_to_percentage(self, score):
        """Convert score to percentage"""
        if score is None:
            return 0.0
        
        if score <= self.perfect_match_threshold:
            # Perfect: 98-100%
            ratio = score / self.perfect_match_threshold
            return 100.0 - ratio * 2.0
        
        # Normal: exponential decay
        return max(0.0, min(98.0, 98.0 * np.exp(-score * 3.0)))
    
    def save_results(self, all_results, reports_dir, timestamp):
        """Save analysis results"""
        # Summary CSV
        summary_data = []
        for result in all_results:
            row = {
                'Gem_ID': result['gem_id'],
                'Timestamp': timestamp,
                'GOI_Light_Sources': '+'.join(result['goi_light_sources']),
                'Valid_Database_Gems': '+'.join(result['valid_database_gems']),
                'Light_Sources_Analyzed': '+'.join(result['light_source_results'].keys()),
                'Source_Count': len(result['light_source_results'])
            }
            
            if result['best_match']:
                match = result['best_match']
                row.update({
                    'Best_Match': match['db_gem_id'],
                    'Score': match['score'],
                    'Percentage': match.get('percentage', 0),
                    'Date_Consistent': match.get('date_consistent', False),
                    'Perfect_Count': match.get('perfect_count', 0)
                })
            
            summary_data.append(row)
        
        if summary_data:
            df = pd.DataFrame(summary_data)
            summary_file = reports_dir / f"structural_analysis_{timestamp}.csv"
            df.to_csv(summary_file, index=False)
            print(f"üìÑ Summary saved: {summary_file.name}")
        
        # Full results JSON
        json_file = reports_dir / f"structural_analysis_full_{timestamp}.json"
        with open(json_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        print(f"üìÑ Full results saved: {json_file.name}")
        
        # Formatted report
        self.generate_formatted_report(all_results, reports_dir, timestamp)
    
    def generate_formatted_report(self, all_results, reports_dir, timestamp):
        """Generate formatted text report"""
        if not all_results:
            return
        
        # Find best result
        best_result = None
        best_score = float('inf')
        
        for result in all_results:
            if result['best_match'] and result['best_match']['score'] < best_score:
                best_score = result['best_match']['score']
                best_result = result
        
        if not best_result:
            return
        
        goi_id = best_result['gem_id']
        goi_desc = self.gem_name_map.get(str(goi_id), f"Unknown Gem {goi_id}")
        
        # Generate report
        report = f"""GEMINI STRUCTURAL ANALYSIS RESULTS (AUTOMATIC VALID GEM DETECTION)
Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Analyzer: Multi-Gem with Automatic Valid Gem Detection
Source: {self.input_source}

Analyzed Gem (GOI): {goi_id}
GOI Description: {goi_desc}
GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}
Valid Database Gems: {'+'.join(best_result['valid_database_gems'])}
{'='*80}

ENHANCED FEATURES:
‚úÖ Automatic GOI Light Source Detection
‚úÖ Automatic Valid Database Gem Detection  
‚úÖ Date-Based TS Matching (Same Day Consistency)
‚úÖ Perfect Self-Matching (100% for identical files)
‚úÖ Enhanced Result Formatting

TOP MATCH:
"""
        
        top_match = best_result['best_match']
        top_id = top_match['db_gem_id']
        top_desc = self.gem_name_map.get(str(top_id), f"Unknown Gem {top_id}")
        
        report += f"""Database Gem ID: {top_id}
Description: {top_desc}
Combined Score: {top_match['score']:.4f}
Combined Percentage: {top_match.get('percentage', 0):.2f}%
Light Sources: {', '.join(top_match['light_sources'])} ({len(top_match['light_sources'])})
Date Consistent: {top_match.get('date_consistent', False)}
Perfect Matches: {top_match.get('perfect_count', 0)}

"""
        
        # Self-match analysis
        is_self_match = self.is_self_match(goi_id, top_id)
        if is_self_match:
            if top_match.get('percentage', 0) > 95:
                report += "üéØ EXCELLENT: Perfect self-match achieved!\n\n"
            else:
                report += "‚ö†Ô∏è CONCERN: Self-match detected but score lower than expected\n\n"
        else:
            report += f"üìä Valid cross-match with gem {top_id}\n\n"
        
        # Save report
        report_file = reports_dir / f"structural_summary_gem_{goi_id}_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìÑ Formatted report saved: {report_file.name}")
        print(f"\nüéØ ANALYSIS SUMMARY:")
        print(f"   GOI: {goi_id} ({goi_desc})")
        print(f"   GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}")
        print(f"   Valid Database Gems: {len(best_result['valid_database_gems'])}")
        print(f"   Best Match: {top_id} ({top_desc})")
        print(f"   Score: {top_match['score']:.4f} ({top_match.get('percentage', 0):.2f}%)")
        if is_self_match:
            print(f"   üéØ Self-Match: {'‚úÖ Perfect' if top_match.get('percentage', 0) > 95 else '‚ö†Ô∏è Suboptimal'}")
    
    def generate_plots(self, all_results, graphs_dir, timestamp):
        """Generate summary plots"""
        if not HAS_MATPLOTLIB:
            return
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle('Structural Analysis with Automatic Valid Gem Detection', fontsize=14, fontweight='bold')
            
            # Plot 1: Scores
            scores = []
            perfect_flags = []
            for result in all_results:
                if result['best_match']:
                    scores.append(result['best_match']['score'])
                    perfect_flags.append(result['best_match'].get('perfect_count', 0) > 0)
            
            if scores:
                colors = ['red' if perfect else 'skyblue' for perfect in perfect_flags]
                axes[0, 0].bar(range(len(scores)), scores, color=colors)
                axes[0, 0].set_title('Match Scores (Red = Perfect Self-Match)')
                axes[0, 0].set_ylabel('Score')
                axes[0, 0].grid(True, alpha=0.3)
            
            # Plot 2: Valid gems count
            valid_counts = []
            for result in all_results:
                valid_counts.append(len(result['valid_database_gems']))
            
            if valid_counts:
                axes[0, 1].bar(['Valid Database Gems'], [valid_counts[0]])
                axes[0, 1].set_title('Automatically Detected Valid Gems')
                axes[0, 1].set_ylabel('Count')
                axes[0, 1].grid(True, alpha=0.3)
            
            # Plot 3: Percentage distribution
            percentages = []
            for result in all_results:
                if result['best_match']:
                    percentages.append(result['best_match'].get('percentage', 0))
            
            if percentages:
                axes[1, 0].hist(percentages, bins=15, color='lightgreen', edgecolor='black', alpha=0.7)
                axes[1, 0].set_title('Match Percentage Distribution')
                axes[1, 0].set_xlabel('Percentage (%)')
                axes[1, 0].set_ylabel('Frequency')
                axes[1, 0].grid(True, alpha=0.3)
            
            # Plot 4: Self-match indicator
            perfect_count = sum(perfect_flags) if scores else 0
            normal_count = len(scores) - perfect_count if scores else 0
            
            if perfect_count > 0 or normal_count > 0:
                axes[1, 1].pie([perfect_count, normal_count], 
                             labels=['Perfect Self-Match', 'Normal Match'],
                             colors=['red', 'lightblue'],
                             autopct='%1.1f%%')
                axes[1, 1].set_title('Perfect vs Normal Matches')
            
            plt.tight_layout()
            
            plot_file = graphs_dir / f"analysis_summary_{timestamp}.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìà Summary plot saved: {plot_file.name}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Plot generation failed: {e}")
    
    def run_auto_analysis(self, auto_select_complete=True):
        """Run automatic analysis"""
        print(f"ü§ñ Auto analysis: {self.input_source} source")
        print(f"üéØ Features: Automatic valid gem detection, perfect self-match")
        
        if not self.gem_groups or not self.database_schema:
            print("‚ùå No gems or database not available")
            return False
        
        # Auto-select complete gems
        if auto_select_complete:
            for base_id, data in self.gem_groups.items():
                if all(len(data['files'][ls]) > 0 for ls in ['B', 'L', 'U']):
                    selected = {'files': {}, 'paths': {}}
                    for ls in ['B', 'L', 'U']:
                        selected['files'][ls] = data['files'][ls][0]
                        selected['paths'][ls] = data['paths'][ls][0]
                    self.selected_gems[base_id] = selected
        
        if not self.selected_gems:
            print("‚ùå No complete gems found")
            return False
        
        print(f"‚úÖ Auto-selected {len(self.selected_gems)} complete gems")
        return self.run_analysis()
    
    def run(self):
        """Start GUI"""
        if self.mode == "gui" and self.root:
            self.root.mainloop()

def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
    parser.add_argument("--mode", choices=["gui", "auto"], default="gui")
    parser.add_argument("--input-source", choices=["archive", "current"], default="archive")
    parser.add_argument("--auto-complete", action="store_true", default=True)
    
    args = parser.parse_args()
    
    try:
        print("üöÄ Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
        print(f"   Mode: {args.mode}, Source: {args.input_source}")
        print("   Features: Auto Light Source Detection, Auto Valid Gem Filtering, Perfect Self-Match")
        
        analyzer = MultiGemStructuralAnalyzer(mode=args.mode, input_source=args.input_source)
        
        if args.mode == "gui":
            analyzer.run()
        else:
            success = analyzer.run_auto_analysis(args.auto_complete)
            return success
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()
, '', identifier)  # Remove timestamps
        identifier = re.sub(r'_(structural|halogen|laser|uv)(?:_.*)?
    
    def find_database_matches(self, filtered_db, light_source):
        """Find database matches (already filtered to valid gems)"""
        light_col = self.database_schema.get('light_column')
        
        if light_col and light_col in filtered_db.columns:
            light_mapping = {'B': ['B', 'Halogen', 'halogen'], 
                           'L': ['L', 'Laser', 'laser'], 
                           'U': ['U', 'UV', 'uv']}
            
            light_values = light_mapping.get(light_source, [light_source])
            matches = filtered_db[filtered_db[light_col].isin(light_values)]
        else:
            matches = filtered_db.copy()
        
        # Add date extraction
        file_col = self.database_schema['file_column']
        if file_col in matches.columns:
            matches['extracted_date'] = matches[file_col].apply(self.extract_date_from_filename)
        
        return matches
    
    def calculate_similarity_scores(self, unknown_df, db_matches, light_source, file_path):
        """Calculate similarity with perfect self-match detection"""
        scores = []
        
        file_col = self.database_schema['file_column']
        wl_col = self.database_schema['wavelength_column']
        int_col = self.database_schema['intensity_column']
        
        if not all([file_col, wl_col, int_col]):
            return scores
        
        # Detect unknown data columns
        unknown_wl_col, unknown_int_col = self.detect_unknown_columns(unknown_df)
        if not unknown_wl_col or not unknown_int_col:
            return scores
        
        try:
            unknown_wl = unknown_df[unknown_wl_col].values
            unknown_int = unknown_df[unknown_int_col].values
            
            # Remove NaN
            valid = ~(np.isnan(unknown_wl) | np.isnan(unknown_int))
            unknown_wl = unknown_wl[valid]
            unknown_int = unknown_int[valid]
            
            if len(unknown_wl) < 3:
                return scores
        except:
            return scores
        
        # Extract GOI base ID for self-match detection
        goi_base_id = self.extract_base_id(file_path.name)
        
        # Group database by gem
        for gem_id, gem_data in db_matches.groupby(file_col):
            try:
                if len(gem_data) < 1:
                    continue
                
                # Extract database gem base ID
                db_base_id = self.extract_base_id(str(gem_id))
                
                # Get date info
                dates = gem_data.get('extracted_date', pd.Series([None])).dropna().unique()
                gem_date = dates[0] if len(dates) > 0 else None
                
                db_wl = gem_data[wl_col].values
                db_int = gem_data[int_col].values
                
                # Remove NaN
                db_valid = ~(np.isnan(db_wl) | np.isnan(db_int))
                db_wl = db_wl[db_valid]
                db_int = db_int[db_valid]
                
                if len(db_wl) < 1:
                    continue
                
                # üéØ CRITICAL: Self-match detection
                if goi_base_id and db_base_id and goi_base_id == db_base_id:
                    score = self.compute_perfect_match_score(unknown_wl, unknown_int, db_wl, db_int)
                    if score is not None:
                        print(f"         üéØ PERFECT SELF-MATCH: {file_path.name} ‚Üî {gem_id} (score: {score:.6f})")
                        scores.append({
                            'db_gem_id': gem_id,
                            'score': score,
                            'date': gem_date,
                            'is_perfect': True
                        })
                        continue
                
                # Normal similarity calculation
                score = self.compute_similarity(unknown_wl, unknown_int, db_wl, db_int)
                
                if score is not None and not math.isnan(score):
                    scores.append({
                        'db_gem_id': gem_id,
                        'score': score,
                        'date': gem_date,
                        'is_perfect': False
                    })
            
            except Exception as e:
                continue
        
        return scores
    
    def extract_base_id(self, filename):
        """Extract numeric base ID from filename"""
        # Remove extensions and suffixes
        stem = re.sub(r'\.csv$', '', filename)
        stem = re.sub(r'_(structural|halogen|laser|uv|TS\d+|\d{8}_\d{6}).*$', '', stem)
        
        # Extract leading digits
        match = re.search(r'^[A-Za-z]*(\d+)', stem)
        return match.group(1) if match else None
    
    def detect_unknown_columns(self, df):
        """Detect wavelength and intensity columns"""
        wl_col = int_col = None
        
        for col in df.columns:
            col_lower = col.lower()
            if 'wavelength' in col_lower or col_lower == 'wl':
                wl_col = col
            elif 'intensity' in col_lower or 'value' in col_lower:
                int_col = col
        
        # Fallback to structural format
        if not wl_col and 'Wavelength' in df.columns:
            wl_col = 'Wavelength'
        if not int_col and 'Intensity' in df.columns:
            int_col = 'Intensity'
        elif not int_col and 'Value' in df.columns:
            int_col = 'Value'
        
        # Final fallback: numeric columns
        if not wl_col or not int_col:
            numeric = df.select_dtypes(include=[np.number]).columns.tolist()
            if len(numeric) >= 2:
                wl_col = wl_col or numeric[0]
                int_col = int_col or numeric[1]
        
        return wl_col, int_col
    
    def compute_perfect_match_score(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute perfect match score for identical data"""
        try:
            # Quick similarity checks
            size_ratio = min(len(unknown_wl), len(db_wl)) / max(len(unknown_wl), len(db_wl))
            if size_ratio < 0.7:
                return None
            
            # Range similarity
            unknown_range = (np.min(unknown_wl), np.max(unknown_wl))
            db_range = (np.min(db_wl), np.max(db_wl))
            range_diff = abs(unknown_range[0] - db_range[0]) + abs(unknown_range[1] - db_range[1])
            
            if range_diff > 100.0:
                return None
            
            # Intensity similarity
            unknown_mean = np.mean(unknown_int)
            db_mean = np.mean(db_int)
            
            if max(unknown_mean, db_mean) > 0:
                mean_ratio = abs(unknown_mean - db_mean) / max(unknown_mean, db_mean)
                if mean_ratio > 0.8:
                    return None
            
            # Sample comparison
            sample_size = min(10, len(unknown_wl), len(db_wl))
            unknown_idx = np.linspace(0, len(unknown_wl)-1, sample_size, dtype=int)
            db_idx = np.linspace(0, len(db_wl)-1, sample_size, dtype=int)
            
            total_diff = 0.0
            for u_i, d_i in zip(unknown_idx, db_idx):
                wl_diff = abs(unknown_wl[u_i] - db_wl[d_i])
                max_int = max(unknown_int[u_i], db_int[d_i])
                int_diff = abs(unknown_int[u_i] - db_int[d_i]) / max_int if max_int > 0 else 0
                total_diff += (wl_diff * 0.01 + int_diff)
            
            avg_diff = total_diff / sample_size
            
            # Perfect match criteria
            if avg_diff < 0.4 and size_ratio > 0.8 and range_diff < 50.0:
                return 0.001 + avg_diff * 0.01  # 0.001-0.005 range
            
            return None
            
        except:
            return None
    
    def compute_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute normal similarity score"""
        try:
            # Check for UV data (811nm)
            has_uv = (np.any((unknown_wl >= 800) & (unknown_wl <= 900)) or 
                     np.any((db_wl >= 800) & (db_wl <= 900)))
            
            if has_uv or any(abs(wl - 811.0) < 5 for wl in unknown_wl):
                return self.compute_uv_similarity(unknown_wl, unknown_int, db_wl, db_int)
            else:
                return self.compute_structural_similarity(unknown_wl, unknown_int, db_wl, db_int)
        except:
            return None
    
    def compute_uv_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """UV-specific similarity (811nm normalization)"""
        try:
            # Find 811nm reference
            unknown_811 = self.find_811nm_intensity(unknown_wl, unknown_int)
            db_811 = self.find_811nm_intensity(db_wl, db_int)
            
            if not unknown_811 or not db_811:
                return None
            
            # Calculate ratios
            unknown_ratios = {float(wl): float(intensity / unknown_811) 
                            for wl, intensity in zip(unknown_wl, unknown_int) if intensity > 0}
            db_ratios = {float(wl): float(intensity / db_811) 
                        for wl, intensity in zip(db_wl, db_int) if intensity > 0}
            
            # Compare ratios
            matched = 0
            total_diff = 0.0
            
            for u_wl, u_ratio in unknown_ratios.items():
                best_match = None
                best_distance = float('inf')
                
                for d_wl, d_ratio in db_ratios.items():
                    distance = abs(u_wl - d_wl)
                    if distance <= 5.0 and distance < best_distance:
                        best_distance = distance
                        best_match = d_ratio
                
                if best_match is not None:
                    ratio_diff = abs(u_ratio - best_match) / max(u_ratio, best_match)
                    total_diff += ratio_diff
                    matched += 1
            
            if matched > 0:
                avg_diff = total_diff / matched
                coverage = matched / len(unknown_ratios)
                return avg_diff * (2.0 - coverage)  # Penalty for poor coverage
            
            return None
            
        except:
            return None
    
    def find_811nm_intensity(self, wavelengths, intensities):
        """Find 811nm reference intensity"""
        # Look for exact match
        exact = np.abs(wavelengths - 811.0) < 0.5
        if np.any(exact):
            return intensities[exact][0]
        
        # Look within tolerance
        tolerance = np.abs(wavelengths - 811.0) <= 5.0
        if np.any(tolerance):
            nearby_wl = wavelengths[tolerance]
            nearby_int = intensities[tolerance]
            return np.interp(811.0, nearby_wl, nearby_int)
        
        # Use proxy (highest in 800-850nm range)
        proxy = (wavelengths >= 800) & (wavelengths <= 850)
        if np.any(proxy):
            return np.max(intensities[proxy])
        
        return None
    
    def compute_structural_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Structural similarity for B/L light sources"""
        try:
            total_score = 0.0
            matched = 0
            tolerance = 10.0
            
            unique_wl = np.unique(unknown_wl)
            
            for u_wl in unique_wl:
                distances = np.abs(db_wl - u_wl)
                nearby = distances <= tolerance
                
                if np.any(nearby):
                    u_int = unknown_int[np.abs(unknown_wl - u_wl) < 0.1]
                    d_int = db_int[nearby]
                    
                    if len(u_int) > 0 and len(d_int) > 0:
                        u_avg = np.mean(u_int)
                        d_avg = np.mean(d_int)
                        
                        if max(u_avg, d_avg) > 0:
                            diff = abs(u_avg - d_avg) / max(u_avg, d_avg)
                            weight = 1.0 - (np.min(distances[nearby]) / tolerance)
                            total_score += diff * weight
                            matched += 1
                else:
                    total_score += 2.0  # Penalty for no match
            
            if len(unique_wl) > 0:
                avg_score = total_score / len(unique_wl)
                match_rate = matched / len(unique_wl)
                return avg_score * (1.2 - match_rate * 0.2)
            
            return None
            
        except:
            return None
    
    def calculate_combined_scores(self, light_source_results):
        """Calculate combined scores with DATE consistency"""
        gem_combinations = {}
        
        # Collect all combinations
        for ls, ls_data in light_source_results.items():
            for match in ls_data['top_5']:
                gem_id = match['db_gem_id']
                gem_date = match.get('date')
                
                if gem_id not in gem_combinations:
                    gem_combinations[gem_id] = {}
                
                gem_combinations[gem_id][ls] = {
                    'score': match['score'],
                    'percentage': self.score_to_percentage(match['score']),
                    'date': gem_date,
                    'is_perfect': match.get('is_perfect', False)
                }
        
        # Check date consistency
        valid_combinations = []
        
        for gem_id, light_data in gem_combinations.items():
            # Get all dates for this gem
            dates = set()
            for ls_info in light_data.values():
                if ls_info['date']:
                    dates.add(ls_info['date'])
            
            # Only allow same-date combinations
            if len(dates) <= 1:  # All same date or no dates
                light_scores = {}
                perfect_count = 0
                
                for ls, ls_info in light_data.items():
                    light_scores[ls] = ls_info['percentage']
                    if ls_info['is_perfect']:
                        perfect_count += 1
                
                if light_scores:
                    # Weighted average
                    weights = {'B': 1.0, 'L': 0.9, 'U': 0.8}
                    weighted_sum = sum(score * weights.get(ls, 1.0) for ls, score in light_scores.items())
                    total_weight = sum(weights.get(ls, 1.0) for ls in light_scores.keys())
                    
                    avg_percentage = weighted_sum / total_weight
                    
                    # Bonuses
                    completeness = 1.0 if len(light_scores) == 3 else 0.8
                    perfect_bonus = 1.0 + perfect_count * 0.05
                    
                    final_percentage = avg_percentage * completeness * perfect_bonus
                    final_percentage = min(100.0, final_percentage)
                    
                    # Convert back to score (lower is better)
                    combined_score = max(0.0, (100.0 - final_percentage) / 25.0)
                    
                    valid_combinations.append({
                        'db_gem_id': gem_id,
                        'score': combined_score,
                        'percentage': final_percentage,
                        'light_sources': list(light_scores.keys()),
                        'date': list(dates)[0] if dates else None,
                        'perfect_count': perfect_count,
                        'date_consistent': True
                    })
        
        return valid_combinations
    
    def score_to_percentage(self, score):
        """Convert score to percentage"""
        if score is None:
            return 0.0
        
        if score <= self.perfect_match_threshold:
            # Perfect: 98-100%
            ratio = score / self.perfect_match_threshold
            return 100.0 - ratio * 2.0
        
        # Normal: exponential decay
        return max(0.0, min(98.0, 98.0 * np.exp(-score * 3.0)))
    
    def save_results(self, all_results, reports_dir, timestamp):
        """Save analysis results"""
        # Summary CSV
        summary_data = []
        for result in all_results:
            row = {
                'Gem_ID': result['gem_id'],
                'Timestamp': timestamp,
                'GOI_Light_Sources': '+'.join(result['goi_light_sources']),
                'Valid_Database_Gems': '+'.join(result['valid_database_gems']),
                'Light_Sources_Analyzed': '+'.join(result['light_source_results'].keys()),
                'Source_Count': len(result['light_source_results'])
            }
            
            if result['best_match']:
                match = result['best_match']
                row.update({
                    'Best_Match': match['db_gem_id'],
                    'Score': match['score'],
                    'Percentage': match.get('percentage', 0),
                    'Date_Consistent': match.get('date_consistent', False),
                    'Perfect_Count': match.get('perfect_count', 0)
                })
            
            summary_data.append(row)
        
        if summary_data:
            df = pd.DataFrame(summary_data)
            summary_file = reports_dir / f"structural_analysis_{timestamp}.csv"
            df.to_csv(summary_file, index=False)
            print(f"üìÑ Summary saved: {summary_file.name}")
        
        # Full results JSON
        json_file = reports_dir / f"structural_analysis_full_{timestamp}.json"
        with open(json_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        print(f"üìÑ Full results saved: {json_file.name}")
        
        # Formatted report
        self.generate_formatted_report(all_results, reports_dir, timestamp)
    
    def generate_formatted_report(self, all_results, reports_dir, timestamp):
        """Generate formatted text report"""
        if not all_results:
            return
        
        # Find best result
        best_result = None
        best_score = float('inf')
        
        for result in all_results:
            if result['best_match'] and result['best_match']['score'] < best_score:
                best_score = result['best_match']['score']
                best_result = result
        
        if not best_result:
            return
        
        goi_id = best_result['gem_id']
        goi_desc = self.gem_name_map.get(str(goi_id), f"Unknown Gem {goi_id}")
        
        # Generate report
        report = f"""GEMINI STRUCTURAL ANALYSIS RESULTS (AUTOMATIC VALID GEM DETECTION)
Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Analyzer: Multi-Gem with Automatic Valid Gem Detection
Source: {self.input_source}

Analyzed Gem (GOI): {goi_id}
GOI Description: {goi_desc}
GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}
Valid Database Gems: {'+'.join(best_result['valid_database_gems'])}
{'='*80}

ENHANCED FEATURES:
‚úÖ Automatic GOI Light Source Detection
‚úÖ Automatic Valid Database Gem Detection  
‚úÖ Date-Based TS Matching (Same Day Consistency)
‚úÖ Perfect Self-Matching (100% for identical files)
‚úÖ Enhanced Result Formatting

TOP MATCH:
"""
        
        top_match = best_result['best_match']
        top_id = top_match['db_gem_id']
        top_desc = self.gem_name_map.get(str(top_id), f"Unknown Gem {top_id}")
        
        report += f"""Database Gem ID: {top_id}
Description: {top_desc}
Combined Score: {top_match['score']:.4f}
Combined Percentage: {top_match.get('percentage', 0):.2f}%
Light Sources: {', '.join(top_match['light_sources'])} ({len(top_match['light_sources'])})
Date Consistent: {top_match.get('date_consistent', False)}
Perfect Matches: {top_match.get('perfect_count', 0)}

"""
        
        # Self-match analysis
        is_self_match = self.is_self_match(goi_id, top_id)
        if is_self_match:
            if top_match.get('percentage', 0) > 95:
                report += "üéØ EXCELLENT: Perfect self-match achieved!\n\n"
            else:
                report += "‚ö†Ô∏è CONCERN: Self-match detected but score lower than expected\n\n"
        else:
            report += f"üìä Valid cross-match with gem {top_id}\n\n"
        
        # Save report
        report_file = reports_dir / f"structural_summary_gem_{goi_id}_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìÑ Formatted report saved: {report_file.name}")
        print(f"\nüéØ ANALYSIS SUMMARY:")
        print(f"   GOI: {goi_id} ({goi_desc})")
        print(f"   GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}")
        print(f"   Valid Database Gems: {len(best_result['valid_database_gems'])}")
        print(f"   Best Match: {top_id} ({top_desc})")
        print(f"   Score: {top_match['score']:.4f} ({top_match.get('percentage', 0):.2f}%)")
        if is_self_match:
            print(f"   üéØ Self-Match: {'‚úÖ Perfect' if top_match.get('percentage', 0) > 95 else '‚ö†Ô∏è Suboptimal'}")
    
    def generate_plots(self, all_results, graphs_dir, timestamp):
        """Generate summary plots"""
        if not HAS_MATPLOTLIB:
            return
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle('Structural Analysis with Automatic Valid Gem Detection', fontsize=14, fontweight='bold')
            
            # Plot 1: Scores
            scores = []
            perfect_flags = []
            for result in all_results:
                if result['best_match']:
                    scores.append(result['best_match']['score'])
                    perfect_flags.append(result['best_match'].get('perfect_count', 0) > 0)
            
            if scores:
                colors = ['red' if perfect else 'skyblue' for perfect in perfect_flags]
                axes[0, 0].bar(range(len(scores)), scores, color=colors)
                axes[0, 0].set_title('Match Scores (Red = Perfect Self-Match)')
                axes[0, 0].set_ylabel('Score')
                axes[0, 0].grid(True, alpha=0.3)
            
            # Plot 2: Valid gems count
            valid_counts = []
            for result in all_results:
                valid_counts.append(len(result['valid_database_gems']))
            
            if valid_counts:
                axes[0, 1].bar(['Valid Database Gems'], [valid_counts[0]])
                axes[0, 1].set_title('Automatically Detected Valid Gems')
                axes[0, 1].set_ylabel('Count')
                axes[0, 1].grid(True, alpha=0.3)
            
            # Plot 3: Percentage distribution
            percentages = []
            for result in all_results:
                if result['best_match']:
                    percentages.append(result['best_match'].get('percentage', 0))
            
            if percentages:
                axes[1, 0].hist(percentages, bins=15, color='lightgreen', edgecolor='black', alpha=0.7)
                axes[1, 0].set_title('Match Percentage Distribution')
                axes[1, 0].set_xlabel('Percentage (%)')
                axes[1, 0].set_ylabel('Frequency')
                axes[1, 0].grid(True, alpha=0.3)
            
            # Plot 4: Self-match indicator
            perfect_count = sum(perfect_flags) if scores else 0
            normal_count = len(scores) - perfect_count if scores else 0
            
            if perfect_count > 0 or normal_count > 0:
                axes[1, 1].pie([perfect_count, normal_count], 
                             labels=['Perfect Self-Match', 'Normal Match'],
                             colors=['red', 'lightblue'],
                             autopct='%1.1f%%')
                axes[1, 1].set_title('Perfect vs Normal Matches')
            
            plt.tight_layout()
            
            plot_file = graphs_dir / f"analysis_summary_{timestamp}.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìà Summary plot saved: {plot_file.name}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Plot generation failed: {e}")
    
    def run_auto_analysis(self, auto_select_complete=True):
        """Run automatic analysis"""
        print(f"ü§ñ Auto analysis: {self.input_source} source")
        print(f"üéØ Features: Automatic valid gem detection, perfect self-match")
        
        if not self.gem_groups or not self.database_schema:
            print("‚ùå No gems or database not available")
            return False
        
        # Auto-select complete gems
        if auto_select_complete:
            for base_id, data in self.gem_groups.items():
                if all(len(data['files'][ls]) > 0 for ls in ['B', 'L', 'U']):
                    selected = {'files': {}, 'paths': {}}
                    for ls in ['B', 'L', 'U']:
                        selected['files'][ls] = data['files'][ls][0]
                        selected['paths'][ls] = data['paths'][ls][0]
                    self.selected_gems[base_id] = selected
        
        if not self.selected_gems:
            print("‚ùå No complete gems found")
            return False
        
        print(f"‚úÖ Auto-selected {len(self.selected_gems)} complete gems")
        return self.run_analysis()
    
    def run(self):
        """Start GUI"""
        if self.mode == "gui" and self.root:
            self.root.mainloop()

def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
    parser.add_argument("--mode", choices=["gui", "auto"], default="gui")
    parser.add_argument("--input-source", choices=["archive", "current"], default="archive")
    parser.add_argument("--auto-complete", action="store_true", default=True)
    
    args = parser.parse_args()
    
    try:
        print("üöÄ Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
        print(f"   Mode: {args.mode}, Source: {args.input_source}")
        print("   Features: Auto Light Source Detection, Auto Valid Gem Filtering, Perfect Self-Match")
        
        analyzer = MultiGemStructuralAnalyzer(mode=args.mode, input_source=args.input_source)
        
        if args.mode == "gui":
            analyzer.run()
        else:
            success = analyzer.run_auto_analysis(args.auto_complete)
            return success
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()
, '', identifier)  # Remove suffixes
        
        # Look for patterns like: 197BC3, 197LC3, 197UC1, 199BC3, etc.
        # Pattern: [digits][letters][digits]
        match = re.search(r'(\d+[A-Z]+\d+)', identifier.upper())
        if match:
            detailed_id = match.group(1)
            return detailed_id
        
        # Fallback: look for base numeric ID only
        base_match = re.search(r'(\d+)', identifier)
        if base_match:
            return base_match.group(1)
        
        return None
    
    def find_database_matches(self, filtered_db, light_source):
        """Find database matches (already filtered to valid gems)"""
        light_col = self.database_schema.get('light_column')
        
        if light_col and light_col in filtered_db.columns:
            light_mapping = {'B': ['B', 'Halogen', 'halogen'], 
                           'L': ['L', 'Laser', 'laser'], 
                           'U': ['U', 'UV', 'uv']}
            
            light_values = light_mapping.get(light_source, [light_source])
            matches = filtered_db[filtered_db[light_col].isin(light_values)]
        else:
            matches = filtered_db.copy()
        
        # Add date extraction
        file_col = self.database_schema['file_column']
        if file_col in matches.columns:
            matches['extracted_date'] = matches[file_col].apply(self.extract_date_from_filename)
        
        return matches
    
    def calculate_similarity_scores(self, unknown_df, db_matches, light_source, file_path):
        """Calculate similarity with perfect self-match detection"""
        scores = []
        
        file_col = self.database_schema['file_column']
        wl_col = self.database_schema['wavelength_column']
        int_col = self.database_schema['intensity_column']
        
        if not all([file_col, wl_col, int_col]):
            return scores
        
        # Detect unknown data columns
        unknown_wl_col, unknown_int_col = self.detect_unknown_columns(unknown_df)
        if not unknown_wl_col or not unknown_int_col:
            return scores
        
        try:
            unknown_wl = unknown_df[unknown_wl_col].values
            unknown_int = unknown_df[unknown_int_col].values
            
            # Remove NaN
            valid = ~(np.isnan(unknown_wl) | np.isnan(unknown_int))
            unknown_wl = unknown_wl[valid]
            unknown_int = unknown_int[valid]
            
            if len(unknown_wl) < 3:
                return scores
        except:
            return scores
        
        # Extract GOI base ID for self-match detection
        goi_base_id = self.extract_base_id(file_path.name)
        
        # Group database by gem
        for gem_id, gem_data in db_matches.groupby(file_col):
            try:
                if len(gem_data) < 1:
                    continue
                
                # Extract database gem base ID
                db_base_id = self.extract_base_id(str(gem_id))
                
                # Get date info
                dates = gem_data.get('extracted_date', pd.Series([None])).dropna().unique()
                gem_date = dates[0] if len(dates) > 0 else None
                
                db_wl = gem_data[wl_col].values
                db_int = gem_data[int_col].values
                
                # Remove NaN
                db_valid = ~(np.isnan(db_wl) | np.isnan(db_int))
                db_wl = db_wl[db_valid]
                db_int = db_int[db_valid]
                
                if len(db_wl) < 1:
                    continue
                
                # üéØ CRITICAL: Self-match detection
                if goi_base_id and db_base_id and goi_base_id == db_base_id:
                    score = self.compute_perfect_match_score(unknown_wl, unknown_int, db_wl, db_int)
                    if score is not None:
                        print(f"         üéØ PERFECT SELF-MATCH: {file_path.name} ‚Üî {gem_id} (score: {score:.6f})")
                        scores.append({
                            'db_gem_id': gem_id,
                            'score': score,
                            'date': gem_date,
                            'is_perfect': True
                        })
                        continue
                
                # Normal similarity calculation
                score = self.compute_similarity(unknown_wl, unknown_int, db_wl, db_int)
                
                if score is not None and not math.isnan(score):
                    scores.append({
                        'db_gem_id': gem_id,
                        'score': score,
                        'date': gem_date,
                        'is_perfect': False
                    })
            
            except Exception as e:
                continue
        
        return scores
    
    def extract_base_id(self, filename):
        """Extract numeric base ID from filename"""
        # Remove extensions and suffixes
        stem = re.sub(r'\.csv$', '', filename)
        stem = re.sub(r'_(structural|halogen|laser|uv|TS\d+|\d{8}_\d{6}).*$', '', stem)
        
        # Extract leading digits
        match = re.search(r'^[A-Za-z]*(\d+)', stem)
        return match.group(1) if match else None
    
    def detect_unknown_columns(self, df):
        """Detect wavelength and intensity columns"""
        wl_col = int_col = None
        
        for col in df.columns:
            col_lower = col.lower()
            if 'wavelength' in col_lower or col_lower == 'wl':
                wl_col = col
            elif 'intensity' in col_lower or 'value' in col_lower:
                int_col = col
        
        # Fallback to structural format
        if not wl_col and 'Wavelength' in df.columns:
            wl_col = 'Wavelength'
        if not int_col and 'Intensity' in df.columns:
            int_col = 'Intensity'
        elif not int_col and 'Value' in df.columns:
            int_col = 'Value'
        
        # Final fallback: numeric columns
        if not wl_col or not int_col:
            numeric = df.select_dtypes(include=[np.number]).columns.tolist()
            if len(numeric) >= 2:
                wl_col = wl_col or numeric[0]
                int_col = int_col or numeric[1]
        
        return wl_col, int_col
    
    def compute_perfect_match_score(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute perfect match score for identical data"""
        try:
            # Quick similarity checks
            size_ratio = min(len(unknown_wl), len(db_wl)) / max(len(unknown_wl), len(db_wl))
            if size_ratio < 0.7:
                return None
            
            # Range similarity
            unknown_range = (np.min(unknown_wl), np.max(unknown_wl))
            db_range = (np.min(db_wl), np.max(db_wl))
            range_diff = abs(unknown_range[0] - db_range[0]) + abs(unknown_range[1] - db_range[1])
            
            if range_diff > 100.0:
                return None
            
            # Intensity similarity
            unknown_mean = np.mean(unknown_int)
            db_mean = np.mean(db_int)
            
            if max(unknown_mean, db_mean) > 0:
                mean_ratio = abs(unknown_mean - db_mean) / max(unknown_mean, db_mean)
                if mean_ratio > 0.8:
                    return None
            
            # Sample comparison
            sample_size = min(10, len(unknown_wl), len(db_wl))
            unknown_idx = np.linspace(0, len(unknown_wl)-1, sample_size, dtype=int)
            db_idx = np.linspace(0, len(db_wl)-1, sample_size, dtype=int)
            
            total_diff = 0.0
            for u_i, d_i in zip(unknown_idx, db_idx):
                wl_diff = abs(unknown_wl[u_i] - db_wl[d_i])
                max_int = max(unknown_int[u_i], db_int[d_i])
                int_diff = abs(unknown_int[u_i] - db_int[d_i]) / max_int if max_int > 0 else 0
                total_diff += (wl_diff * 0.01 + int_diff)
            
            avg_diff = total_diff / sample_size
            
            # Perfect match criteria
            if avg_diff < 0.4 and size_ratio > 0.8 and range_diff < 50.0:
                return 0.001 + avg_diff * 0.01  # 0.001-0.005 range
            
            return None
            
        except:
            return None
    
    def compute_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Compute normal similarity score"""
        try:
            # Check for UV data (811nm)
            has_uv = (np.any((unknown_wl >= 800) & (unknown_wl <= 900)) or 
                     np.any((db_wl >= 800) & (db_wl <= 900)))
            
            if has_uv or any(abs(wl - 811.0) < 5 for wl in unknown_wl):
                return self.compute_uv_similarity(unknown_wl, unknown_int, db_wl, db_int)
            else:
                return self.compute_structural_similarity(unknown_wl, unknown_int, db_wl, db_int)
        except:
            return None
    
    def compute_uv_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """UV-specific similarity (811nm normalization)"""
        try:
            # Find 811nm reference
            unknown_811 = self.find_811nm_intensity(unknown_wl, unknown_int)
            db_811 = self.find_811nm_intensity(db_wl, db_int)
            
            if not unknown_811 or not db_811:
                return None
            
            # Calculate ratios
            unknown_ratios = {float(wl): float(intensity / unknown_811) 
                            for wl, intensity in zip(unknown_wl, unknown_int) if intensity > 0}
            db_ratios = {float(wl): float(intensity / db_811) 
                        for wl, intensity in zip(db_wl, db_int) if intensity > 0}
            
            # Compare ratios
            matched = 0
            total_diff = 0.0
            
            for u_wl, u_ratio in unknown_ratios.items():
                best_match = None
                best_distance = float('inf')
                
                for d_wl, d_ratio in db_ratios.items():
                    distance = abs(u_wl - d_wl)
                    if distance <= 5.0 and distance < best_distance:
                        best_distance = distance
                        best_match = d_ratio
                
                if best_match is not None:
                    ratio_diff = abs(u_ratio - best_match) / max(u_ratio, best_match)
                    total_diff += ratio_diff
                    matched += 1
            
            if matched > 0:
                avg_diff = total_diff / matched
                coverage = matched / len(unknown_ratios)
                return avg_diff * (2.0 - coverage)  # Penalty for poor coverage
            
            return None
            
        except:
            return None
    
    def find_811nm_intensity(self, wavelengths, intensities):
        """Find 811nm reference intensity"""
        # Look for exact match
        exact = np.abs(wavelengths - 811.0) < 0.5
        if np.any(exact):
            return intensities[exact][0]
        
        # Look within tolerance
        tolerance = np.abs(wavelengths - 811.0) <= 5.0
        if np.any(tolerance):
            nearby_wl = wavelengths[tolerance]
            nearby_int = intensities[tolerance]
            return np.interp(811.0, nearby_wl, nearby_int)
        
        # Use proxy (highest in 800-850nm range)
        proxy = (wavelengths >= 800) & (wavelengths <= 850)
        if np.any(proxy):
            return np.max(intensities[proxy])
        
        return None
    
    def compute_structural_similarity(self, unknown_wl, unknown_int, db_wl, db_int):
        """Structural similarity for B/L light sources"""
        try:
            total_score = 0.0
            matched = 0
            tolerance = 10.0
            
            unique_wl = np.unique(unknown_wl)
            
            for u_wl in unique_wl:
                distances = np.abs(db_wl - u_wl)
                nearby = distances <= tolerance
                
                if np.any(nearby):
                    u_int = unknown_int[np.abs(unknown_wl - u_wl) < 0.1]
                    d_int = db_int[nearby]
                    
                    if len(u_int) > 0 and len(d_int) > 0:
                        u_avg = np.mean(u_int)
                        d_avg = np.mean(d_int)
                        
                        if max(u_avg, d_avg) > 0:
                            diff = abs(u_avg - d_avg) / max(u_avg, d_avg)
                            weight = 1.0 - (np.min(distances[nearby]) / tolerance)
                            total_score += diff * weight
                            matched += 1
                else:
                    total_score += 2.0  # Penalty for no match
            
            if len(unique_wl) > 0:
                avg_score = total_score / len(unique_wl)
                match_rate = matched / len(unique_wl)
                return avg_score * (1.2 - match_rate * 0.2)
            
            return None
            
        except:
            return None
    
    def calculate_combined_scores(self, light_source_results):
        """Calculate combined scores with DATE consistency"""
        gem_combinations = {}
        
        # Collect all combinations
        for ls, ls_data in light_source_results.items():
            for match in ls_data['top_5']:
                gem_id = match['db_gem_id']
                gem_date = match.get('date')
                
                if gem_id not in gem_combinations:
                    gem_combinations[gem_id] = {}
                
                gem_combinations[gem_id][ls] = {
                    'score': match['score'],
                    'percentage': self.score_to_percentage(match['score']),
                    'date': gem_date,
                    'is_perfect': match.get('is_perfect', False)
                }
        
        # Check date consistency
        valid_combinations = []
        
        for gem_id, light_data in gem_combinations.items():
            # Get all dates for this gem
            dates = set()
            for ls_info in light_data.values():
                if ls_info['date']:
                    dates.add(ls_info['date'])
            
            # Only allow same-date combinations
            if len(dates) <= 1:  # All same date or no dates
                light_scores = {}
                perfect_count = 0
                
                for ls, ls_info in light_data.items():
                    light_scores[ls] = ls_info['percentage']
                    if ls_info['is_perfect']:
                        perfect_count += 1
                
                if light_scores:
                    # Weighted average
                    weights = {'B': 1.0, 'L': 0.9, 'U': 0.8}
                    weighted_sum = sum(score * weights.get(ls, 1.0) for ls, score in light_scores.items())
                    total_weight = sum(weights.get(ls, 1.0) for ls in light_scores.keys())
                    
                    avg_percentage = weighted_sum / total_weight
                    
                    # Bonuses
                    completeness = 1.0 if len(light_scores) == 3 else 0.8
                    perfect_bonus = 1.0 + perfect_count * 0.05
                    
                    final_percentage = avg_percentage * completeness * perfect_bonus
                    final_percentage = min(100.0, final_percentage)
                    
                    # Convert back to score (lower is better)
                    combined_score = max(0.0, (100.0 - final_percentage) / 25.0)
                    
                    valid_combinations.append({
                        'db_gem_id': gem_id,
                        'score': combined_score,
                        'percentage': final_percentage,
                        'light_sources': list(light_scores.keys()),
                        'date': list(dates)[0] if dates else None,
                        'perfect_count': perfect_count,
                        'date_consistent': True
                    })
        
        return valid_combinations
    
    def score_to_percentage(self, score):
        """Convert score to percentage"""
        if score is None:
            return 0.0
        
        if score <= self.perfect_match_threshold:
            # Perfect: 98-100%
            ratio = score / self.perfect_match_threshold
            return 100.0 - ratio * 2.0
        
        # Normal: exponential decay
        return max(0.0, min(98.0, 98.0 * np.exp(-score * 3.0)))
    
    def save_results(self, all_results, reports_dir, timestamp):
        """Save analysis results"""
        # Summary CSV
        summary_data = []
        for result in all_results:
            row = {
                'Gem_ID': result['gem_id'],
                'Timestamp': timestamp,
                'GOI_Light_Sources': '+'.join(result['goi_light_sources']),
                'Valid_Database_Gems': '+'.join(result['valid_database_gems']),
                'Light_Sources_Analyzed': '+'.join(result['light_source_results'].keys()),
                'Source_Count': len(result['light_source_results'])
            }
            
            if result['best_match']:
                match = result['best_match']
                row.update({
                    'Best_Match': match['db_gem_id'],
                    'Score': match['score'],
                    'Percentage': match.get('percentage', 0),
                    'Date_Consistent': match.get('date_consistent', False),
                    'Perfect_Count': match.get('perfect_count', 0)
                })
            
            summary_data.append(row)
        
        if summary_data:
            df = pd.DataFrame(summary_data)
            summary_file = reports_dir / f"structural_analysis_{timestamp}.csv"
            df.to_csv(summary_file, index=False)
            print(f"üìÑ Summary saved: {summary_file.name}")
        
        # Full results JSON
        json_file = reports_dir / f"structural_analysis_full_{timestamp}.json"
        with open(json_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        print(f"üìÑ Full results saved: {json_file.name}")
        
        # Formatted report
        self.generate_formatted_report(all_results, reports_dir, timestamp)
    
    def generate_formatted_report(self, all_results, reports_dir, timestamp):
        """Generate formatted text report"""
        if not all_results:
            return
        
        # Find best result
        best_result = None
        best_score = float('inf')
        
        for result in all_results:
            if result['best_match'] and result['best_match']['score'] < best_score:
                best_score = result['best_match']['score']
                best_result = result
        
        if not best_result:
            return
        
        goi_id = best_result['gem_id']
        goi_desc = self.gem_name_map.get(str(goi_id), f"Unknown Gem {goi_id}")
        
        # Generate report
        report = f"""GEMINI STRUCTURAL ANALYSIS RESULTS (AUTOMATIC VALID GEM DETECTION)
Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Analyzer: Multi-Gem with Automatic Valid Gem Detection
Source: {self.input_source}

Analyzed Gem (GOI): {goi_id}
GOI Description: {goi_desc}
GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}
Valid Database Gems: {'+'.join(best_result['valid_database_gems'])}
{'='*80}

ENHANCED FEATURES:
‚úÖ Automatic GOI Light Source Detection
‚úÖ Automatic Valid Database Gem Detection  
‚úÖ Date-Based TS Matching (Same Day Consistency)
‚úÖ Perfect Self-Matching (100% for identical files)
‚úÖ Enhanced Result Formatting

TOP MATCH:
"""
        
        top_match = best_result['best_match']
        top_id = top_match['db_gem_id']
        top_desc = self.gem_name_map.get(str(top_id), f"Unknown Gem {top_id}")
        
        report += f"""Database Gem ID: {top_id}
Description: {top_desc}
Combined Score: {top_match['score']:.4f}
Combined Percentage: {top_match.get('percentage', 0):.2f}%
Light Sources: {', '.join(top_match['light_sources'])} ({len(top_match['light_sources'])})
Date Consistent: {top_match.get('date_consistent', False)}
Perfect Matches: {top_match.get('perfect_count', 0)}

"""
        
        # Self-match analysis
        is_self_match = self.is_self_match(goi_id, top_id)
        if is_self_match:
            if top_match.get('percentage', 0) > 95:
                report += "üéØ EXCELLENT: Perfect self-match achieved!\n\n"
            else:
                report += "‚ö†Ô∏è CONCERN: Self-match detected but score lower than expected\n\n"
        else:
            report += f"üìä Valid cross-match with gem {top_id}\n\n"
        
        # Save report
        report_file = reports_dir / f"structural_summary_gem_{goi_id}_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìÑ Formatted report saved: {report_file.name}")
        print(f"\nüéØ ANALYSIS SUMMARY:")
        print(f"   GOI: {goi_id} ({goi_desc})")
        print(f"   GOI Light Sources: {'+'.join(best_result['goi_light_sources'])}")
        print(f"   Valid Database Gems: {len(best_result['valid_database_gems'])}")
        print(f"   Best Match: {top_id} ({top_desc})")
        print(f"   Score: {top_match['score']:.4f} ({top_match.get('percentage', 0):.2f}%)")
        if is_self_match:
            print(f"   üéØ Self-Match: {'‚úÖ Perfect' if top_match.get('percentage', 0) > 95 else '‚ö†Ô∏è Suboptimal'}")
    
    def generate_plots(self, all_results, graphs_dir, timestamp):
        """Generate summary plots"""
        if not HAS_MATPLOTLIB:
            return
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle('Structural Analysis with Automatic Valid Gem Detection', fontsize=14, fontweight='bold')
            
            # Plot 1: Scores
            scores = []
            perfect_flags = []
            for result in all_results:
                if result['best_match']:
                    scores.append(result['best_match']['score'])
                    perfect_flags.append(result['best_match'].get('perfect_count', 0) > 0)
            
            if scores:
                colors = ['red' if perfect else 'skyblue' for perfect in perfect_flags]
                axes[0, 0].bar(range(len(scores)), scores, color=colors)
                axes[0, 0].set_title('Match Scores (Red = Perfect Self-Match)')
                axes[0, 0].set_ylabel('Score')
                axes[0, 0].grid(True, alpha=0.3)
            
            # Plot 2: Valid gems count
            valid_counts = []
            for result in all_results:
                valid_counts.append(len(result['valid_database_gems']))
            
            if valid_counts:
                axes[0, 1].bar(['Valid Database Gems'], [valid_counts[0]])
                axes[0, 1].set_title('Automatically Detected Valid Gems')
                axes[0, 1].set_ylabel('Count')
                axes[0, 1].grid(True, alpha=0.3)
            
            # Plot 3: Percentage distribution
            percentages = []
            for result in all_results:
                if result['best_match']:
                    percentages.append(result['best_match'].get('percentage', 0))
            
            if percentages:
                axes[1, 0].hist(percentages, bins=15, color='lightgreen', edgecolor='black', alpha=0.7)
                axes[1, 0].set_title('Match Percentage Distribution')
                axes[1, 0].set_xlabel('Percentage (%)')
                axes[1, 0].set_ylabel('Frequency')
                axes[1, 0].grid(True, alpha=0.3)
            
            # Plot 4: Self-match indicator
            perfect_count = sum(perfect_flags) if scores else 0
            normal_count = len(scores) - perfect_count if scores else 0
            
            if perfect_count > 0 or normal_count > 0:
                axes[1, 1].pie([perfect_count, normal_count], 
                             labels=['Perfect Self-Match', 'Normal Match'],
                             colors=['red', 'lightblue'],
                             autopct='%1.1f%%')
                axes[1, 1].set_title('Perfect vs Normal Matches')
            
            plt.tight_layout()
            
            plot_file = graphs_dir / f"analysis_summary_{timestamp}.png"
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìà Summary plot saved: {plot_file.name}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Plot generation failed: {e}")
    
    def run_auto_analysis(self, auto_select_complete=True):
        """Run automatic analysis"""
        print(f"ü§ñ Auto analysis: {self.input_source} source")
        print(f"üéØ Features: Automatic valid gem detection, perfect self-match")
        
        if not self.gem_groups or not self.database_schema:
            print("‚ùå No gems or database not available")
            return False
        
        # Auto-select complete gems
        if auto_select_complete:
            for base_id, data in self.gem_groups.items():
                if all(len(data['files'][ls]) > 0 for ls in ['B', 'L', 'U']):
                    selected = {'files': {}, 'paths': {}}
                    for ls in ['B', 'L', 'U']:
                        selected['files'][ls] = data['files'][ls][0]
                        selected['paths'][ls] = data['paths'][ls][0]
                    self.selected_gems[base_id] = selected
        
        if not self.selected_gems:
            print("‚ùå No complete gems found")
            return False
        
        print(f"‚úÖ Auto-selected {len(self.selected_gems)} complete gems")
        return self.run_analysis()
    
    def run(self):
        """Start GUI"""
        if self.mode == "gui" and self.root:
            self.root.mainloop()

def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
    parser.add_argument("--mode", choices=["gui", "auto"], default="gui")
    parser.add_argument("--input-source", choices=["archive", "current"], default="archive")
    parser.add_argument("--auto-complete", action="store_true", default=True)
    
    args = parser.parse_args()
    
    try:
        print("üöÄ Multi-Gem Structural Analyzer with Automatic Valid Gem Detection")
        print(f"   Mode: {args.mode}, Source: {args.input_source}")
        print("   Features: Auto Light Source Detection, Auto Valid Gem Filtering, Perfect Self-Match")
        
        analyzer = MultiGemStructuralAnalyzer(mode=args.mode, input_source=args.input_source)
        
        if args.mode == "gui":
            analyzer.run()
        else:
            success = analyzer.run_auto_analysis(args.auto_complete)
            return success
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()
